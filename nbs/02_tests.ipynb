{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!pip install -r ../requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dialog System\n",
    "> Functtions to test `dialog_system`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#import let_me_answer_for_you as lmafy \n",
    "from let_me_answer_for_you import dialog_system\n",
    "\n",
    "from unittest.mock import patch\n",
    "@patch('__main__.dialog_system.get_input')\n",
    "def test_dialog_system(mock_input):\n",
    "    mock_input.side_effect =['hola']\n",
    "    print(dialog_system.get_input('Hola'))\n",
    "test_dialog_system()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 06:33:57.507 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "06:33:57 INFO:Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "2020-06-18 06:34:24.134 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec download because of matching hashes\n",
      "06:34:24 INFO:Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec download because of matching hashes\n",
      "2020-06-18 06:34:24.754 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "06:34:24 INFO:Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "2020-06-18 06:34:24.759 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "06:34:24 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-18 06:34:28.293 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "06:34:28 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-18 06:34:29.67 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "06:34:29 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-18 06:34:29.166 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "06:34:29 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-18 06:34:29.267 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "06:34:29 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-18 06:34:29.338 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "06:34:29 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-18 06:34:40.22 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "06:34:40 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "2020-06-18 06:34:48.418 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz download because of matching hashes\n",
      "06:34:48 INFO:Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz download because of matching hashes\n",
      "2020-06-18 06:34:54.556 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "06:34:54 INFO:Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "2020-06-18 06:35:27.367 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "06:35:27 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "2020-06-18 06:36:23.735 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "06:36:23 INFO:Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "100%|██████████| 12.3k/12.3k [00:00<00:00, 6.80MB/s]\n",
      "2020-06-18 06:36:24.669 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "06:36:24 INFO:Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "2020-06-18 06:36:32.872 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "06:36:32 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-18 06:36:32.916 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "06:36:32 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-18 06:36:32.920 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "06:36:32 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-18 06:36:35.428 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "06:36:35 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-18 06:36:36.292 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "06:36:36 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-18 06:36:36.300 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "06:36:36 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-18 06:36:36.403 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "06:36:36 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-18 06:36:36.411 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "06:36:36 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-18 06:36:36.419 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "06:36:36 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-18 06:36:36.424 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "06:36:36 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-18 06:36:36.599 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "06:36:36 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "2020-06-18 06:36:37.728 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "06:36:37 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-18 06:36:45.837 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "06:36:45 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-18 06:36:45.839 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "06:36:45 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-18 06:36:45.839 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "06:36:45 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-18 06:36:45.841 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "06:36:45 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-18 06:36:45.843 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "06:36:45 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-18 06:36:45.844 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "06:36:45 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-18 06:36:45.845 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "06:36:45 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-18 06:36:48.692 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "06:36:48 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-18 06:36:48.856 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "06:36:48 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-18 06:36:48.859 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "06:36:48 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-18 06:36:48.868 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "06:36:48 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-18 06:36:48.966 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "06:36:48 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-18 06:36:48.971 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "06:36:48 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-18 06:36:48.974 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "06:36:48 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Introduce question:\n",
      " Who is Elon Musk?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Elon Musk?:\n",
      "\n",
      "0: Elon Musk is the CEO of Tesla\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Give a better answer [y/n]? y\n",
      "Give the answer as a context [y/n]? y\n",
      "Give context a title:\n",
      " Tesla\n",
      "Introduce the context:\n",
      " Tesla is electricar company, is currently the only car company left in california. It was founded by Elon Musk in 2010\n",
      "Introduce question:\n",
      " Who is Elon Musk?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Elon Musk?:\n",
      "\n",
      "0: Elon Musk is the CEO of Tesla\n",
      "1: electricar company\n",
      "2: Tesla is electricar company\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Give a better answer [y/n]? n\n",
      "Introduce question:\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 06:47:16.286 INFO in 'deeppavlov.models.squad.squad'['squad'] at line 298: SQuAD model: Warning! Empty question or context was found.\n",
      "06:47:16 INFO:SQuAD model: Warning! Empty question or context was found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "0: Elon Musk is the CEO of Tesla\n",
      "1: Tesla is electricar company, is currently the only car company left in california\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Give a better answer [y/n]? n\n",
      "Introduce question:\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 06:47:25.288 INFO in 'deeppavlov.models.squad.squad'['squad'] at line 298: SQuAD model: Warning! Empty question or context was found.\n",
      "06:47:25 INFO:SQuAD model: Warning! Empty question or context was found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "0: Elon Musk is the CEO of Tesla\n",
      "1: Tesla is electricar company, is currently the only car company left in california\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Give a better answer [y/n]? n\n",
      "Introduce question:\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-18 06:49:51.255 INFO in 'deeppavlov.models.squad.squad'['squad'] at line 298: SQuAD model: Warning! Empty question or context was found.\n",
      "06:49:51 INFO:SQuAD model: Warning! Empty question or context was found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "0: Elon Musk is the CEO of Tesla\n",
      "1: Tesla is electricar company, is currently the only car company left in california\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Give a better answer [y/n]? \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0fa87a927569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlet_me_answer_for_you\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdialog_system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdialog_system\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialog_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/wd/nbs/let_me_answer_for_you/dialog_system.py\u001b[0m in \u001b[0;36mdialog_system\u001b[0;34m(context_data_file, faq_data_file, configs_faq)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqa_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqa_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Goodbye!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/wd/nbs/let_me_answer_for_you/dialog_system.py\u001b[0m in \u001b[0;36mquestion_response\u001b[0;34m(data, qa_models, num_returned_values_per_squad_model)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_responses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformatted_responses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqa_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/wd/nbs/let_me_answer_for_you/dialog_system.py\u001b[0m in \u001b[0;36mnew_answer\u001b[0;34m(question, data, qa_models)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnew_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqa_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mget_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Give a better answer [y/n]?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'no data updates..'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "from let_me_answer_for_you import dialog_system\n",
    "dialog_system.dialog_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:10:23 DEBUG: pip install deeppavlov\n",
      "10:10:25 DEBUG:Requirement already satisfied: deeppavlov in /opt/conda/lib/python3.7/site-packages (0.10.0)\n",
      "Requirement already satisfied: sacremoses==0.0.35 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.0.35)\n",
      "Requirement already satisfied: overrides==2.7.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn==0.21.2 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.21.2)\n",
      "Requirement already satisfied: h5py==2.10.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.10.0)\n",
      "Requirement already satisfied: pyopenssl==19.1.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (19.1.0)\n",
      "Requirement already satisfied: pymorphy2==0.8 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.8)\n",
      "Requirement already satisfied: pytelegrambotapi==3.6.7 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (3.6.7)\n",
      "Requirement already satisfied: pytz==2019.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2019.1)\n",
      "Requirement already satisfied: tqdm==4.41.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (4.41.1)\n",
      "Requirement already satisfied: ruamel.yaml==0.15.100 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.15.100)\n",
      "Requirement already satisfied: pandas==0.25.3 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.25.3)\n",
      "Requirement already satisfied: pydantic==1.3 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.3)\n",
      "Requirement already satisfied: rusenttokenize==0.0.5 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.0.5)\n",
      "Requirement already satisfied: scipy==1.4.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.4.1)\n",
      "Requirement already satisfied: requests==2.22.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.22.0)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.4.404381.4453942)\n",
      "Requirement already satisfied: nltk==3.4.5 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (3.4.5)\n",
      "Requirement already satisfied: numpy==1.18.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.18.0)\n",
      "Requirement already satisfied: Cython==0.29.14 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.29.14)\n",
      "Requirement already satisfied: aio-pika==6.4.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (6.4.1)\n",
      "Requirement already satisfied: fastapi==0.47.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.47.1)\n",
      "Requirement already satisfied: uvicorn==0.11.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.11.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.35->deeppavlov) (0.15.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.35->deeppavlov) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.35->deeppavlov) (1.14.0)\n",
      "Requirement already satisfied: cryptography>=2.8 in /opt/conda/lib/python3.7/site-packages (from pyopenssl==19.1.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
      "Requirement already satisfied: aiormq<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from aio-pika==6.4.1->deeppavlov) (3.2.2)\n",
      "Requirement already satisfied: yarl in /opt/conda/lib/python3.7/site-packages (from aio-pika==6.4.1->deeppavlov) (1.4.2)\n",
      "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /opt/conda/lib/python3.7/site-packages (from fastapi==0.47.1->deeppavlov) (0.12.9)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (0.9.0)\n",
      "Requirement already satisfied: websockets==8.* in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (8.1)\n",
      "Requirement already satisfied: httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (0.0.13)\n",
      "Requirement already satisfied: uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.0)\n",
      "Requirement already satisfied: pamqp==2.3.0 in /opt/conda/lib/python3.7/site-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov) (2.3.0)\n",
      "Requirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.7/site-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.7.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
      "\n",
      "10:10:25 DEBUG: python -m deeppavlov install squad\n",
      "10:10:50 DEBUG:Collecting tensorflow==1.15.2\n",
      "  Using cached tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.12.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.29.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.18.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.34.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (46.0.0.post20200311)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n",
      "Installing collected packages: tensorflow\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.15.3\n",
      "    Uninstalling tensorflow-1.15.3:\n",
      "      Successfully uninstalled tensorflow-1.15.3\n",
      "Successfully installed tensorflow-1.15.2\n",
      "\n",
      "10:10:50 DEBUG: python -m deeppavlov install squad_bert\n",
      "10:11:06 DEBUG:Requirement already satisfied: tensorflow==1.15.2 in /opt/conda/lib/python3.7/site-packages (1.15.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.18.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.12.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.29.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (46.0.0.post20200311)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n",
      "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
      "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-oa7isr77\n",
      "Requirement already satisfied (use --upgrade to upgrade): bert-dp==1.0 from git+https://github.com/deepmipt/bert.git@feat/multi_gpu in /opt/conda/lib/python3.7/site-packages\n",
      "Building wheels for collected packages: bert-dp\n",
      "  Building wheel for bert-dp (setup.py): started\n",
      "  Building wheel for bert-dp (setup.py): finished with status 'done'\n",
      "  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23580 sha256=c1cc5c900cec573de2d962fe9d0c363ff1f583ffa4d673bacb38573b7b96555d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p0pud0mk/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb\n",
      "Successfully built bert-dp\n",
      "\n",
      "10:11:06 DEBUG: python -m deeppavlov install fasttext_avg_autofaq\n",
      "10:11:08 DEBUG:Requirement already satisfied: fasttext==0.9.1 in /opt/conda/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (1.18.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (2.5.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (46.0.0.post20200311)\n",
      "\n",
      "10:11:08 DEBUG: python -m deeppavlov install fasttext_tfidf_autofaq\n",
      "10:11:10 DEBUG:Requirement already satisfied: fasttext==0.9.1 in /opt/conda/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (46.0.0.post20200311)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (2.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (1.18.0)\n",
      "\n",
      "10:11:10 DEBUG: python -m deeppavlov install tfidf_autofaq\n",
      "10:11:11 DEBUG:\n",
      "10:11:11 DEBUG: python -m deeppavlov install tfidf_logreg_autofaq \n",
      "10:11:12 DEBUG:\n",
      "10:11:12 DEBUG: python -m deeppavlov install tfidf_logreg_en_faq\n",
      "10:11:16 DEBUG:Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /opt/conda/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.0.0.post20200311)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "Requirement already satisfied: spacy==2.2.3 in /opt/conda/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (46.0.0.post20200311)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (0.6.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.18.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (7.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (2.0.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (1.5.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3) (4.41.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (3.1.0)\n",
      "\n",
      "10:11:16 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "10:11:16 DEBUG:http://files.deeppavlov.ai:80 \"GET /embeddings/wiki-news-300d-1M-char.vec.md5 HTTP/1.1\" 200 61\n",
      "2020-06-17 22:11:17.124 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "10:11:17 INFO:Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "10:11:17 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "10:11:17 DEBUG:http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz.md5 HTTP/1.1\" 200 389\n",
      "2020-06-17 22:11:23.998 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "10:11:23 INFO:Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "10:11:24 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "10:11:24 DEBUG:http://files.deeppavlov.ai:80 \"GET /embeddings/wiki-news-300d-1M.vec.md5 HTTP/1.1\" 200 56\n"
     ]
    }
   ],
   "source": [
    "from unittest.mock import patch\n",
    "@patch('__main__.dialog_system.get_input')\n",
    "def test_dialog_system(mock_input):\n",
    "    mock_input.side_effect =['Is this ']\n",
    "    ds = dialog_system.dialog_system()\n",
    "    #print(dialog_system.get_input('Hola'))\n",
    "test_dialog_system()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
