{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:27:20 INFO:Hello! Welcome to our automated dialog system!\n",
      "09:27:20 DEBUG:test: for Debug?\n",
      "09:27:20 ERROR: Error Log Active \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!pip install -r ../requirements.txt > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dialog_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:27:23 INFO:Hello! Welcome to our automated dialog system!\n",
      "09:27:23 DEBUG:test: for Debug?\n",
      "09:27:23 ERROR: Error Log Active \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# export\n",
    "from deeppavlov import configs,build_model,train_model\n",
    "import json\n",
    "from os import path,popen,mkdir\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from collections import defaultdict \n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "logging.info(\"Hello! Welcome to our automated dialog system!\")\n",
    "logging.debug(\"test: for Debug?\")\n",
    "logging.error(' Error Log Active ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_shell_installs():\n",
    "    ''' Run install commands\n",
    "    '''\n",
    "    command_strings = (\n",
    "        ' pip install deeppavlov',\n",
    "        ' python -m deeppavlov install squad',\n",
    "        ' python -m deeppavlov install squad_bert',\n",
    "        ' python -m deeppavlov install fasttext_avg_autofaq',\n",
    "        ' python -m deeppavlov install fasttext_tfidf_autofaq',\n",
    "        ' python -m deeppavlov install tfidf_autofaq',\n",
    "        ' python -m deeppavlov install tfidf_logreg_autofaq ',\n",
    "        ' python -m deeppavlov install tfidf_logreg_en_faq'\n",
    "    )\n",
    "    for command in command_strings:\n",
    "        logging.debug(command)\n",
    "        logging.debug(popen(command).read())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialog System\n",
    "> Question Answering Automated Dialog System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:27:23 DEBUG: pip install deeppavlov\n",
      "09:27:25 DEBUG:Requirement already satisfied: deeppavlov in /opt/conda/lib/python3.7/site-packages (0.10.0)\n",
      "Requirement already satisfied: rusenttokenize==0.0.5 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.0.5)\n",
      "Requirement already satisfied: overrides==2.7.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.7.0)\n",
      "Requirement already satisfied: pyopenssl==19.1.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (19.1.0)\n",
      "Requirement already satisfied: pandas==0.25.3 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.25.3)\n",
      "Requirement already satisfied: sacremoses==0.0.35 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.0.35)\n",
      "Requirement already satisfied: fastapi==0.47.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.47.1)\n",
      "Requirement already satisfied: ruamel.yaml==0.15.100 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.15.100)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.4.404381.4453942)\n",
      "Requirement already satisfied: tqdm==4.41.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (4.41.1)\n",
      "Requirement already satisfied: pytz==2019.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2019.1)\n",
      "Requirement already satisfied: pymorphy2==0.8 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.8)\n",
      "Requirement already satisfied: nltk==3.4.5 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (3.4.5)\n",
      "Requirement already satisfied: Cython==0.29.14 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.29.14)\n",
      "Requirement already satisfied: pytelegrambotapi==3.6.7 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (3.6.7)\n",
      "Requirement already satisfied: aio-pika==6.4.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (6.4.1)\n",
      "Requirement already satisfied: scipy==1.4.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.4.1)\n",
      "Requirement already satisfied: requests==2.22.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.22.0)\n",
      "Requirement already satisfied: uvicorn==0.11.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.11.1)\n",
      "Requirement already satisfied: scikit-learn==0.21.2 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.21.2)\n",
      "Requirement already satisfied: h5py==2.10.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.10.0)\n",
      "Requirement already satisfied: pydantic==1.3 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.3)\n",
      "Requirement already satisfied: numpy==1.18.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.18.0)\n",
      "Requirement already satisfied: cryptography>=2.8 in /opt/conda/lib/python3.7/site-packages (from pyopenssl==19.1.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.7/site-packages (from pyopenssl==19.1.0->deeppavlov) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.35->deeppavlov) (0.15.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses==0.0.35->deeppavlov) (7.1.2)\n",
      "Requirement already satisfied: starlette<=0.12.9,>=0.12.9 in /opt/conda/lib/python3.7/site-packages (from fastapi==0.47.1->deeppavlov) (0.12.9)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8->deeppavlov) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8->deeppavlov) (2.4.393442.3710985)\n",
      "Requirement already satisfied: docopt>=0.6 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
      "Requirement already satisfied: yarl in /opt/conda/lib/python3.7/site-packages (from aio-pika==6.4.1->deeppavlov) (1.4.2)\n",
      "Requirement already satisfied: aiormq<4,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from aio-pika==6.4.1->deeppavlov) (3.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0->deeppavlov) (1.25.7)\n",
      "Requirement already satisfied: uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: websockets==8.* in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (8.1)\n",
      "Requirement already satisfied: httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\" in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (0.0.13)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1->deeppavlov) (0.9.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.0)\n",
      "Requirement already satisfied: multidict>=4.0 in /opt/conda/lib/python3.7/site-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.7.6)\n",
      "Requirement already satisfied: pamqp==2.3.0 in /opt/conda/lib/python3.7/site-packages (from aiormq<4,>=3.2.0->aio-pika==6.4.1->deeppavlov) (2.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
      "\n",
      "09:27:25 DEBUG: python -m deeppavlov install squad\n",
      "09:27:46 DEBUG:Collecting tensorflow==1.15.2\n",
      "  Using cached tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.18.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.29.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.34.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.12.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.14.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (46.0.0.post20200311)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n",
      "Installing collected packages: tensorflow\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.15.3\n",
      "    Uninstalling tensorflow-1.15.3:\n",
      "      Successfully uninstalled tensorflow-1.15.3\n",
      "Successfully installed tensorflow-1.15.2\n",
      "\n",
      "09:27:46 DEBUG: python -m deeppavlov install squad_bert\n",
      "09:27:53 DEBUG:Requirement already satisfied: tensorflow==1.15.2 in /opt/conda/lib/python3.7/site-packages (1.15.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.2.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.34.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.29.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.12.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.18.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.12.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.14.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (46.0.0.post20200311)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n",
      "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
      "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-fe6lwwze\n",
      "Requirement already satisfied (use --upgrade to upgrade): bert-dp==1.0 from git+https://github.com/deepmipt/bert.git@feat/multi_gpu in /opt/conda/lib/python3.7/site-packages\n",
      "Building wheels for collected packages: bert-dp\n",
      "  Building wheel for bert-dp (setup.py): started\n",
      "  Building wheel for bert-dp (setup.py): finished with status 'done'\n",
      "  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23580 sha256=b43861c8352474583c2d5b9b73d09626b8b7a720379397d15feb4099b635de37\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kxdf7dm1/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb\n",
      "Successfully built bert-dp\n",
      "\n",
      "09:27:53 DEBUG: python -m deeppavlov install fasttext_avg_autofaq\n",
      "09:27:55 DEBUG:Requirement already satisfied: fasttext==0.9.1 in /opt/conda/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (1.18.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (2.5.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (46.0.0.post20200311)\n",
      "\n",
      "09:27:55 DEBUG: python -m deeppavlov install fasttext_tfidf_autofaq\n",
      "09:27:57 DEBUG:Requirement already satisfied: fasttext==0.9.1 in /opt/conda/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (1.18.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (2.5.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (46.0.0.post20200311)\n",
      "\n",
      "09:27:57 DEBUG: python -m deeppavlov install tfidf_autofaq\n",
      "09:27:58 DEBUG:\n",
      "09:27:58 DEBUG: python -m deeppavlov install tfidf_logreg_autofaq \n",
      "09:27:59 DEBUG:\n",
      "09:27:59 DEBUG: python -m deeppavlov install tfidf_logreg_en_faq\n",
      "09:28:03 DEBUG:Requirement already satisfied: spacy==2.2.3 in /opt/conda/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (2.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (46.0.0.post20200311)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (0.6.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (7.3.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.18.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (3.1.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /opt/conda/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.0.0.post20200311)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_shell_installs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def action_over_list_f(arr, v):\n",
    "\n",
    "    k_id, v_id = next(iter(v[0].items()))\n",
    "\n",
    "    for p, a in enumerate(arr):\n",
    "        if k_id in a.keys() and a[k_id] == v_id:\n",
    "            for k_rep, v_rep in v[1].items():\n",
    "                arr[p][k_rep] = v_rep\n",
    "\n",
    "\n",
    "def replacement_f(model_config, **args):\n",
    "    '''Replaces the model config dictionary with new values\n",
    "    '''\n",
    "    for k, v in args.items():\n",
    "        if isinstance(v, dict):\n",
    "            replacement_f(model_config[k], **v)\n",
    "        if isinstance(v, str):\n",
    "            model_config[k] = v\n",
    "        if isinstance(model_config[k], list):\n",
    "            action_over_list_f(model_config[k], v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test action_over_list_f\n",
    "from random import randint\n",
    "\n",
    "\n",
    "def gen_list_keys_for_tests():\n",
    "\n",
    "    str_n = lambda x: f'{x}_{randint(1,10):1}'\n",
    "    gen_dict_list = lambda: {\n",
    "        'id': str_n('id'),\n",
    "        'key1': str_n('v1'),\n",
    "        'key2': str_n('v2'),\n",
    "        'key3': str_n('v3')\n",
    "    }\n",
    "\n",
    "    pipe_list = [gen_dict_list() for _ in range(randint(3, 10))]\n",
    "\n",
    "    rand_id = pipe_list[randint(0, len(pipe_list) - 1)]['id']\n",
    "    rand_key = f'key{randint(1, 3)}' \n",
    "\n",
    "    new_rand_val = str_n('new')\n",
    "    args = {\n",
    "        'chains': {\n",
    "            'pipe': [{\n",
    "                'id': rand_id\n",
    "            }, {\n",
    "               rand_key : new_rand_val\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return pipe_list, rand_id, rand_key, args, new_rand_val\n",
    "\n",
    "\n",
    "def test_action_over_list_f():\n",
    "\n",
    "    pipe_list, rand_id, rand_key, args, new_rand_val = gen_list_keys_for_tests()\n",
    "\n",
    "    assert all(\n",
    "        new_rand_val not in pipe_elem.values() for pipe_elem in pipe_list\n",
    "    )\n",
    "\n",
    "    action_over_list_f(pipe_list, args['chains']['pipe'])\n",
    "\n",
    "    assert any(\n",
    "        rand_key in pipe_elem.keys() and\n",
    "        new_rand_val in pipe_elem.values() for pipe_elem in pipe_list\n",
    "    )\n",
    "\n",
    "\n",
    "def test_replacement_f_list():\n",
    "\n",
    "    pipe_list, rand_id, rand_key, args, new_rand_val = gen_list_keys_for_tests()\n",
    "\n",
    "    mod_conf = {'chains': {'pipe': pipe_list}}\n",
    "\n",
    "    assert all(\n",
    "        new_rand_val not in pipe_elem.values()\n",
    "        for pipe_elem in mod_conf['chains']['pipe']\n",
    "    )\n",
    "\n",
    "    replacement_f(model_config=mod_conf, **args)\n",
    "    assert any(\n",
    "        rand_key in pipe_elem.keys() and\n",
    "        new_rand_val in pipe_elem.values()\n",
    "        for pipe_elem in mod_conf['chains']['pipe']\n",
    "    )\n",
    "\n",
    "\n",
    "def test_replacement_f_val():\n",
    "    args = {'key3': 'newvalue'}\n",
    "    mod_conf = {'key1': 'val1', 'key2': 'val2', 'key3': 'val3'}\n",
    "    replacement_f(model_config=mod_conf, **args)\n",
    "    assert all(\n",
    "        arg_k in mod_conf.keys() and arg_v in mod_conf.values()\n",
    "        for arg_k, arg_v in args.items()\n",
    "    )\n",
    "\n",
    "\n",
    "def test_replacement_f_dict():\n",
    "    args = {'1_key_3': {'2_key_2': 'newvalue'}}\n",
    "    mod_conf = {'1_key_3': {'2_key_2': 'oldvalue'}, '0_key_': '0_val'}\n",
    "    replacement_f(model_config=mod_conf, **args)\n",
    "    assert mod_conf['1_key_3']['2_key_2'] == 'newvalue'\n",
    "\n",
    "\n",
    "test_action_over_list_f()\n",
    "test_replacement_f_list()\n",
    "test_replacement_f_val()\n",
    "test_replacement_f_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def updates_faq_config_file(\n",
    "    configs_path,\n",
    "    **args\n",
    "):\n",
    "    '''Updates deepplavov json config file \n",
    "    '''\n",
    "    #set FAQ data in config file\n",
    "    model_config = json.load(open(configs_path))\n",
    "\n",
    "    if 'data_url' in model_config['dataset_reader']:\n",
    "        del model_config['dataset_reader']['data_url']\n",
    "\n",
    "    replacement_f(model_config=model_config,**args)\n",
    "\n",
    "    json.dump(model_config, open(configs_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test updates_faq_config_file\n",
    "import tempfile\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "def gen_list_keys_for_tests():\n",
    "\n",
    "    str_n = lambda x: f'{x}_{randint(1,10):1}'\n",
    "    gen_dict_list = lambda: {\n",
    "        'id': str_n('id'),\n",
    "        'key1': str_n('v1'),\n",
    "        'key2': str_n('v2'),\n",
    "        'key3': str_n('v3')\n",
    "    }\n",
    "\n",
    "    pipe_list = [gen_dict_list() for _ in range(randint(3, 10))]\n",
    "\n",
    "    rand_id = pipe_list[randint(0, len(pipe_list) - 1)]['id']\n",
    "    rand_key =  f'key{randint(1, 3)}' \n",
    "\n",
    "    new_rand_val = str_n('new')\n",
    "    pipe_dict = {'pipe': [{'id': rand_id}, {rand_key: new_rand_val}]}\n",
    "    args = {'chainer': pipe_dict}\n",
    "\n",
    "    return pipe_list, rand_id, rand_key, args, new_rand_val\n",
    "\n",
    "\n",
    "def test_updates_faq_config_file_update_string():\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        tmp_config_file = path.join(tmpdirname, 'tmp_file.json')\n",
    "\n",
    "        copyfile(configs.faq.tfidf_logreg_en_faq, tmp_config_file)\n",
    "\n",
    "        assert path.isfile(tmp_config_file)\n",
    "\n",
    "        updates_faq_config_file(\n",
    "            configs_path=tmp_config_file,\n",
    "            dataset_reader={'data_path': 'fictional_csv_file.csv'}\n",
    "        )\n",
    "\n",
    "        config_json = json.load(open(tmp_config_file))\n",
    "        assert 'data_path' in config_json['dataset_reader']\n",
    "\n",
    "\n",
    "def test_updates_faq_config_file_update_list():\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        tmp_config_file = path.join(tmpdirname, 'tmp_file.json')\n",
    "\n",
    "        pipe_list, rand_id, rand_key, args, new_rand_val = gen_list_keys_for_tests(\n",
    "        )\n",
    "        mod_conf = {\n",
    "            'chainer': {\n",
    "                'pipe': pipe_list\n",
    "            },\n",
    "            'dataset_reader': 'dataset_reader_dictionary'\n",
    "        }\n",
    "\n",
    "        json.dump(mod_conf, open(tmp_config_file, 'w'))\n",
    "\n",
    "        assert path.isfile(tmp_config_file)\n",
    "\n",
    "        updates_faq_config_file(configs_path=tmp_config_file, **args)\n",
    "\n",
    "        config_json = json.load(open(tmp_config_file))\n",
    "   \n",
    "        assert any(\n",
    "            rand_key in pipe_elem.keys() and new_rand_val in pipe_elem.values()\n",
    "            for pipe_elem in config_json['chainer']['pipe']\n",
    "        )\n",
    "\n",
    "\n",
    "test_updates_faq_config_file_update_string()\n",
    "test_updates_faq_config_file_update_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def select_faq_responses(faq_model, question):\n",
    "    '''Calls Deeppavlov FAQ model\n",
    "    '''\n",
    "    return faq_model([question])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:28:06 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:07 DEBUG:http://files.deeppavlov.ai:80 \"GET /faq/mipt/en_mipt_faq_v4.tar.gz.md5 HTTP/1.1\" 200 189\n",
      "09:28:08 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:08 DEBUG:http://files.deeppavlov.ai:80 \"GET /faq/mipt/en_mipt_faq_v4.tar.gz HTTP/1.1\" 200 12276\n",
      "2020-06-17 21:28:08.573 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "09:28:08 INFO:Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "100%|██████████| 12.3k/12.3k [00:00<00:00, 6.48MB/s]\n",
      "2020-06-17 21:28:08.602 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "09:28:08 INFO:Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2020-06-17 21:28:16.603 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:16 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:16.604 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:28:16 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:28:16.605 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:16 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:16.702 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:28:16 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:28:16.749 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:16 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:16.773 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /tmp/tmpxkulrt8h/temp_vocab_answers.dict]\n",
      "09:28:16 INFO:[loading vocabulary from /tmp/tmpxkulrt8h/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:16.780 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /tmp/tmpxkulrt8h/temp_vocab_answers.dict]\n",
      "09:28:16 INFO:[saving vocabulary to /tmp/tmpxkulrt8h/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:16.787 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:16 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:16.794 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:28:16 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:28:16.799 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:16 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:16.842 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:28:16 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "09:28:16 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:17 DEBUG:http://files.deeppavlov.ai:80 \"GET /faq/mipt/en_mipt_faq_v4.tar.gz.md5 HTTP/1.1\" 200 189\n",
      "09:28:17 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:17 DEBUG:http://files.deeppavlov.ai:80 \"GET /faq/mipt/en_mipt_faq_v4.tar.gz HTTP/1.1\" 200 12276\n",
      "2020-06-17 21:28:17.678 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "09:28:17 INFO:Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "100%|██████████| 12.3k/12.3k [00:00<00:00, 6.35MB/s]\n",
      "2020-06-17 21:28:17.692 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "09:28:17 INFO:Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "2020-06-17 21:28:18.420 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:18 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:18.421 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:28:18 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:28:18.422 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:18 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:18.427 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:28:18 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:28:18.430 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:18 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:18.432 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "09:28:18 INFO:[loading vocabulary from /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:18.433 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "09:28:18 INFO:[saving vocabulary to /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:18.434 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:18 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:18.435 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:28:18 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:28:18.436 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:18 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:18.441 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:28:18 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:28:18.462 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:18 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:19.209 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:19 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:19.210 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:28:19 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:28:19.211 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:19.213 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "09:28:19 INFO:[loading vocabulary from /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:19.214 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:19 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:19.215 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:28:19 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:28:19.216 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:19.951 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:19 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:19.952 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:28:19 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:28:19.952 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:19.954 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "09:28:19 INFO:[loading vocabulary from /tmp/tmp4bhfcjwg/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:19.956 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:19 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:19.957 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:28:19 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:28:19.957 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:19 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:20 DEBUG:http://files.deeppavlov.ai:80 \"GET /faq/mipt/en_mipt_faq_v4.tar.gz.md5 HTTP/1.1\" 200 189\n",
      "09:28:20 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:20 DEBUG:http://files.deeppavlov.ai:80 \"GET /faq/mipt/en_mipt_faq_v4.tar.gz HTTP/1.1\" 200 12276\n",
      "2020-06-17 21:28:20.784 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "09:28:20 INFO:Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
      "100%|██████████| 12.3k/12.3k [00:00<00:00, 6.32MB/s]\n",
      "2020-06-17 21:28:20.800 INFO in 'deeppavlov.core.data.utils'['utils'] at line 242: Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "09:28:20 INFO:Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt\n",
      "2020-06-17 21:28:21.599 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:21 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:21.601 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:28:21 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:28:21.601 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:21 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:21.606 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:28:21 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:28:21.609 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:21 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:21.610 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "09:28:21 INFO:[loading vocabulary from /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:21.611 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "09:28:21 INFO:[saving vocabulary to /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:21.613 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:21 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:21.614 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:28:21 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:28:21.615 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:21 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:21.620 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:28:21 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:28:21.621 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:21 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:22.309 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:22 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:22.311 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:28:22 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:28:22.311 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:22 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:22.313 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "09:28:22 INFO:[loading vocabulary from /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:22.315 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:22 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:22.323 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:28:22 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:28:22.334 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:22 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:23.90 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:28:23 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:28:23.91 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:28:23 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:28:23.92 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:23 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:28:23.94 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "09:28:23 INFO:[loading vocabulary from /tmp/tmpg6fjh4db/temp_vocab_answers.dict]\n",
      "2020-06-17 21:28:23.96 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:28:23 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:28:23.97 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:28:23 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:28:23.98 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:28:23 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n"
     ]
    }
   ],
   "source": [
    "#test faq responses\n",
    "import tempfile\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "def gen_mock_csv_file(tmpdirname, faqs):\n",
    "\n",
    "    temp_faq_csv = path.join(tmpdirname, 'tmp_faq.csv')\n",
    "\n",
    "    pd.DataFrame(faqs).to_csv(temp_faq_csv, index=False)\n",
    "\n",
    "    return temp_faq_csv\n",
    "\n",
    "\n",
    "def gen_mock_vocab_answers(tmpdirname, vocabs):\n",
    "\n",
    "    temp_dict_file = path.join(tmpdirname, 'temp_vocab_answers.dict')\n",
    "    vocabs_text = '\\n'.join(\n",
    "        t + '\\t' + str(f) for t, f in zip(vocabs['text'], vocabs['freq'])\n",
    "    )\n",
    "\n",
    "    f = open(temp_dict_file, 'w')\n",
    "    f.write(vocabs_text)\n",
    "    f.close()\n",
    "\n",
    "    return temp_dict_file\n",
    "\n",
    "\n",
    "def gen_faq_config(tmpdirname, vocab_file, faq_file):\n",
    "\n",
    "    temp_configs_faq = path.join(tmpdirname, 'temp_config_faq.json')\n",
    "    copyfile(configs.faq.tfidf_logreg_en_faq, temp_configs_faq)\n",
    "\n",
    "    changes_dict = {'save_path': vocab_file, 'load_path': vocab_file}\n",
    "    id_dict = {'id': 'answers_vocab'}\n",
    "\n",
    "    updates_faq_config_file(\n",
    "        configs_path=temp_configs_faq,\n",
    "        chainer={'pipe': [id_dict, changes_dict]},\n",
    "        dataset_reader={'data_path': faq_file}\n",
    "    )\n",
    "\n",
    "    return temp_configs_faq\n",
    "\n",
    "\n",
    "def test_faq_response_with_minimum_faqs_in_dataframe_fail_case():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        faqs = {\n",
    "            'Question': ['Is Covid erradicated?'],\n",
    "            'Answer': ['Definitely not!']\n",
    "        }\n",
    "\n",
    "        vocabs = {'text': ['This is a vocab example'], 'freq': [1]}\n",
    "\n",
    "        faq_file = gen_mock_csv_file(tmpdirname, faqs)\n",
    "        vocab_file = gen_mock_vocab_answers(tmpdirname, vocabs)\n",
    "\n",
    "        configs_file = gen_faq_config(tmpdirname, vocab_file, faq_file)\n",
    "\n",
    "        try:\n",
    "            select_faq_responses(\n",
    "                question='Is Enrique the prettiest person in town?',\n",
    "                faq_model=train_model(configs_file, download=True)\n",
    "            )\n",
    "            assert False\n",
    "        except ValueError as e:\n",
    "            assert True\n",
    "\n",
    "\n",
    "def test_faq_response_with_minimum_faqs_in_dataframe_success_case():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        faqs = {\n",
    "            'Question': ['Is Covid erradicated?', 'Who is the current POTUS?'],\n",
    "            'Answer': ['Definitely not!', 'Donald Trump']\n",
    "        }\n",
    "\n",
    "        vocabs = {'text': ['This is a vocab example'], 'freq': [1]}\n",
    "\n",
    "        faq_file = gen_mock_csv_file(tmpdirname, faqs)\n",
    "        vocab_file = gen_mock_vocab_answers(tmpdirname, vocabs)\n",
    "\n",
    "        configs_file = gen_faq_config(tmpdirname, vocab_file, faq_file)\n",
    "\n",
    "        assert select_faq_responses(\n",
    "            question='Is Enrique the prettiest person in town?',\n",
    "            faq_model=train_model(configs_file, download=True)\n",
    "        ) == ['Donald Trump']\n",
    "\n",
    "        \n",
    "        \n",
    "def test_faq_response_with_minimum_answers_vocab_success_case():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        faqs = {\n",
    "            'Question': ['Is Covid erradicated?', 'Who is the current POTUS?'],\n",
    "            'Answer': ['Definitely not!', 'Donald Trump']\n",
    "        }\n",
    "\n",
    "        vocabs = {'text': [], 'freq': []}\n",
    "\n",
    "        faq_file = gen_mock_csv_file(tmpdirname, faqs)\n",
    "        vocab_file = gen_mock_vocab_answers(tmpdirname, vocabs)\n",
    "\n",
    "        configs_file = gen_faq_config(tmpdirname, vocab_file, faq_file)\n",
    "\n",
    "        select_faq_responses(\n",
    "            question='Is Enrique the prettiest person in town?',\n",
    "            faq_model=train_model(configs_file, download=True)\n",
    "        ) == ['Donald Trump']\n",
    "\n",
    "test_faq_response_with_minimum_faqs_in_dataframe_fail_case()\n",
    "test_faq_response_with_minimum_faqs_in_dataframe_success_case()\n",
    "test_faq_response_with_minimum_answers_vocab_success_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def select_squad_responses(\n",
    "    contexts, squad_model, question, best_results=1\n",
    "):\n",
    "    '''Calls Deeppavlov BERT and RNET Context Question Answering\n",
    "    '''\n",
    "    responses = contexts.context.apply(\n",
    "        lambda context: squad_model([context], [question])\n",
    "    ).values\n",
    "    \n",
    "    logging.debug(f'Responses: {responses}')\n",
    "    top_responses = [\n",
    "        r[0][0] for r in sorted(responses, key=lambda x: -1 * x[2][0])\n",
    "        [:best_results]\n",
    "    ]\n",
    "\n",
    "    logging.debug(f'Top Responses: {top_responses}')\n",
    "    return responses, top_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:28:23 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:23 DEBUG:http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/squad_bert.tar.gz.md5 HTTP/1.1\" 200 184\n",
      "2020-06-17 21:28:30.440 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz download because of matching hashes\n",
      "09:28:30 INFO:Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz download because of matching hashes\n",
      "09:28:30 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:28:30 DEBUG:http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/bert/cased_L-12_H-768_A-12.zip.md5 HTTP/1.1\" 200 386\n",
      "2020-06-17 21:28:36.669 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "09:28:36 INFO:Skipped http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip download because of matching hashes\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:81: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:178: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "09:28:39 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "09:28:39 WARNING:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "09:28:40 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "09:28:40 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "09:28:40 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "09:28:40 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "09:28:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:154: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
      "\n",
      "09:28:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:166: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "09:28:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "09:28:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "09:28:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "09:28:51 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:89: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "09:28:56 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:94: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2020-06-17 21:28:56.570 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:28:56 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:28:56 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "09:28:56 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model\n",
      "09:28:58 DEBUG:Responses: []\n",
      "09:28:58 DEBUG:Top Responses: []\n",
      "09:28:59 DEBUG:Responses: [list([['Elon Musk'], [203], [50257280.0]])]\n",
      "09:28:59 DEBUG:Top Responses: ['Elon Musk']\n",
      "09:29:01 DEBUG:Responses: [list([['TJ'], [44], [6978.86279296875]])\n",
      " list([['north of mexico'], [22], [81567.328125]])]\n",
      "09:29:01 DEBUG:Top Responses: ['north of mexico', 'TJ']\n",
      "09:29:01 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:29:01 DEBUG:http://files.deeppavlov.ai:80 \"GET /embeddings/wiki-news-300d-1M.vec.md5 HTTP/1.1\" 200 56\n",
      "2020-06-17 21:29:31.201 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec download because of matching hashes\n",
      "09:29:31 INFO:Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec download because of matching hashes\n",
      "09:29:31 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:29:31 DEBUG:http://files.deeppavlov.ai:80 \"GET /deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz.md5 HTTP/1.1\" 200 389\n",
      "2020-06-17 21:29:38.765 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "09:29:38 INFO:Skipped http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz download because of matching hashes\n",
      "09:29:38 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80\n",
      "09:29:39 DEBUG:http://files.deeppavlov.ai:80 \"GET /embeddings/wiki-news-300d-1M-char.vec.md5 HTTP/1.1\" 200 61\n",
      "2020-06-17 21:29:39.292 INFO in 'deeppavlov.download'['download'] at line 117: Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "09:29:39 INFO:Skipped http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec download because of matching hashes\n",
      "2020-06-17 21:29:39.302 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "09:29:39 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-17 21:29:39.600 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "09:29:39 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-17 21:29:40.312 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:122: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/layers/tf_layers.py:591: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/layers/tf_layers.py:596: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:133: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:139: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:155: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "2020-06-17 21:29:40.455 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:29:40.598 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:29:40.692 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:40 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/squad/utils.py:101: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "09:29:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/squad/utils.py:139: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "09:29:49 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2020-06-17 21:29:54.183 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:29:54 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:29:54 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model\n",
      "09:29:55 DEBUG:Responses: []\n",
      "09:29:55 DEBUG:Top Responses: []\n",
      "09:29:57 DEBUG:Responses: [list([['Elon Musk'], [203], [36056324.0]])]\n",
      "09:29:57 DEBUG:Top Responses: ['Elon Musk']\n",
      "09:29:57 DEBUG:Responses: [list([['TJ'], [44], [564.4996948242188]])\n",
      " list([['north of mexico'], [22], [138151.90625]])]\n",
      "09:29:57 DEBUG:Top Responses: ['north of mexico', 'TJ']\n"
     ]
    }
   ],
   "source": [
    "#test select_squad_responses\n",
    "import tempfile\n",
    "from shutil import copyfile\n",
    "\n",
    "empty = {'topic': [], 'context': []}\n",
    "spacex = {\n",
    "    'topic': ['SpaceX'],\n",
    "    'context':\n",
    "        [\n",
    "            '''Space Exploration Technologies Corp., trading as SpaceX, is an American aerospace manufacturer and space transportation\n",
    "services company headquartered in Hawthorne, California. It was founded in 2002 by Elon Musk with the goal of reducing space \n",
    "transportation costs to enable the colonization of Mars. SpaceX has developed several launch vehicles, the Starlink satellite\n",
    "constellation, and the Dragon spacecraft. It is widely considered among the most successful private spaceflight companies.'''\n",
    "        ]\n",
    "}\n",
    "\n",
    "intekglobal = {\n",
    "    'topic': ['Intekglobal', 'InG'],\n",
    "    'context':\n",
    "        [\n",
    "            'Intekglobal has its headquarters located in TJ',\n",
    "            'Intekglobal is in the north of mexico'\n",
    "        ]\n",
    "}\n",
    "\n",
    "\n",
    "def assert_squad_model(\n",
    "    contexts, squad_model, question, expected_responses, **args\n",
    "):\n",
    "    responses, top_responses = select_squad_responses(\n",
    "        contexts=pd.DataFrame(contexts),\n",
    "        squad_model=squad_model,\n",
    "        question=question,\n",
    "        **args\n",
    "    )\n",
    "    assert top_responses == expected_responses\n",
    "\n",
    "\n",
    "def test_squad_bert():\n",
    "\n",
    "    bert = build_model(configs.squad.squad_bert, download=True)\n",
    "\n",
    "    assert_squad_model(\n",
    "        empty,\n",
    "        bert,\n",
    "        'Is an empty response expected?',\n",
    "        expected_responses=[],\n",
    "        best_results=2\n",
    "    )\n",
    "\n",
    "    assert_squad_model(\n",
    "        spacex, bert, 'Who founded SpaceX?', expected_responses=['Elon Musk']\n",
    "    )\n",
    "\n",
    "    assert_squad_model(\n",
    "        intekglobal,\n",
    "        bert,\n",
    "        'Where is Intekglobal located?',\n",
    "        expected_responses=['north of mexico','TJ'],\n",
    "        best_results=2\n",
    "    )\n",
    "\n",
    "\n",
    "def test_squad_rnet():\n",
    "\n",
    "    bert = build_model(configs.squad.squad, download=True)\n",
    "\n",
    "    assert_squad_model(\n",
    "        empty,\n",
    "        bert,\n",
    "        'Is an empty response expected?',\n",
    "        expected_responses=[],\n",
    "        best_results=5\n",
    "    )\n",
    "\n",
    "    assert_squad_model(\n",
    "        spacex, bert, 'Who founded SpaceX?', expected_responses=['Elon Musk']\n",
    "    )\n",
    "\n",
    "    assert_squad_model(\n",
    "        intekglobal,\n",
    "        bert,\n",
    "        'Where is Intekglobal located?',\n",
    "        expected_responses=['north of mexico','TJ'],\n",
    "        best_results=2\n",
    "    )\n",
    "\n",
    "test_squad_bert()\n",
    "test_squad_rnet()\n",
    "del spacex, empty, intekglobal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_qa_models(\n",
    "    config_rnet=configs.squad.squad,\n",
    "    config_bert=configs.squad.squad_bert,\n",
    "    config_tfidf=configs.faq.tfidf_logreg_en_faq,\n",
    "    download=True\n",
    "):\n",
    "    qa_models = {\n",
    "        'squad':\n",
    "            {\n",
    "                'rnet': build_model(config_rnet, download=download),\n",
    "                'bert': build_model(config_bert, download=download)\n",
    "            },\n",
    "        'faq': {\n",
    "            'tfidf': train_model(config_tfidf, download=download)\n",
    "        }\n",
    "    }\n",
    "    return qa_models\n",
    "\n",
    "\n",
    "def format_responses(question, responses):\n",
    "    formatted_response = f'{question}:\\n\\n'\n",
    "    for k, res in enumerate(responses):\n",
    "        formatted_response += f'{k}: {res}\\n'\n",
    "    return formatted_response\n",
    "\n",
    "\n",
    "def get_responses(contexts, question, qa_models, nb_squad_results=1):\n",
    "    responses = []\n",
    "    for squad_model in qa_models['squad'].values():\n",
    "        responses.extend(\n",
    "            select_squad_responses(\n",
    "                contexts, squad_model, question, best_results=nb_squad_results\n",
    "            )[1]\n",
    "        )\n",
    "    for faq_model in qa_models['faq'].values():\n",
    "        responses.extend(select_faq_responses(faq_model, question))\n",
    "    return responses, format_responses(\n",
    "        question, set([r for r in responses if r.strip()])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-17 21:29:57.312 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "09:29:57 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-17 21:29:57.609 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "09:29:57 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-17 21:29:58.319 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:58 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:29:58.448 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:58 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:29:58.569 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:58 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:29:58.653 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:29:58 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:30:11.919 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:30:11 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:30:12 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model\n",
      "2020-06-17 21:30:29.392 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:30:29 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:30:29 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model\n",
      "2020-06-17 21:30:31.679 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:30:31 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:30:31.680 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:30:31 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:30:31.681 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:30:31 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:30:31.687 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:30:31 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:30:31.689 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:30:31 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:30:31.692 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:30:31 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:30:31.707 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:30:31 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:30:31.710 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:30:31 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:30:31.712 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:30:31 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:30:31.712 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:30:31 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:30:31.720 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:30:31 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:30:31.723 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:30:31 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:30:32.465 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:30:32 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:30:32.466 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:30:32 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:30:32.467 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:30:32 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:30:32.469 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:30:32 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:30:32.473 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:30:32 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:30:32.475 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:30:32 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:30:32.478 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:30:32 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:30:33.256 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:30:33 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:30:33.257 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:30:33 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:30:33.258 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:30:33 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:30:33.261 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:30:33 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:30:33.264 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:30:33 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:30:33.265 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:30:33 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:30:33.266 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:30:33 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:30:34 DEBUG:Responses: [list([['TJ'], [44], [120.95974731445312]])\n",
      " list([['north of mexico'], [22], [174602.40625]])]\n",
      "09:30:34 DEBUG:Top Responses: ['north of mexico', 'TJ']\n",
      "09:30:37 DEBUG:Responses: [list([['TJ'], [44], [22507.34375]])\n",
      " list([['north of mexico'], [22], [269778.3125]])]\n",
      "09:30:37 DEBUG:Top Responses: ['north of mexico', 'TJ']\n",
      "09:30:37 DEBUG:['north of mexico', 'TJ', 'north of mexico', 'TJ', 'Yes it is!']\n",
      "09:30:37 DEBUG:Where is Intekglobal?:\n",
      "\n",
      "0: north of mexico\n",
      "1: Yes it is!\n",
      "2: TJ\n",
      "\n",
      "2020-06-17 21:30:37.188 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "09:30:37 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-17 21:30:37.514 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "09:30:37 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-17 21:30:38.165 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:30:38 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:30:38.296 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:30:38 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:30:38.429 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:30:38 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:30:38.523 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:30:38 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:30:51.684 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:30:51 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:30:51 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model\n",
      "2020-06-17 21:31:08.413 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:31:08 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:31:08 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model\n",
      "2020-06-17 21:31:12.45 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:12 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:12.47 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:31:12 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:31:12.49 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:12 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:12.62 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:31:12 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:31:12.66 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:12 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:12.69 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:12 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:12.71 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:12 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:12.73 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:12 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:12.75 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:31:12 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:31:12.77 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:12 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:12.86 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:31:12 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:31:12.89 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:12 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:12.932 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:12 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:12.934 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:31:12 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:31:12.935 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:12 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:12.937 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:12 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:12.939 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:12 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:12.941 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:31:12 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:31:12.941 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:12 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:13.801 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:13 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:13.804 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:31:13 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:31:13.805 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:13 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:13.808 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:13 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:13.810 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:13 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:13.811 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:31:13 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:31:13.812 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:13 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:13 DEBUG:Responses: []\n",
      "09:31:13 DEBUG:Top Responses: []\n",
      "09:31:13 DEBUG:Responses: []\n",
      "09:31:13 DEBUG:Top Responses: []\n",
      "09:31:13 DEBUG:['Two']\n",
      "09:31:13 DEBUG:What is the minimun number of FAQ questions:\n",
      "\n",
      "0: Two\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test get_responses\n",
    "import tempfile\n",
    "from shutil import copyfile\n",
    "\n",
    "intekglobal_context = {\n",
    "    'topic': ['Intekglobal', 'InG'],\n",
    "    'context':\n",
    "        [\n",
    "            'Intekglobal has its headquarters located in TJ',\n",
    "            'Intekglobal is in the north of mexico'\n",
    "        ]\n",
    "}\n",
    "\n",
    "intekglobal_faqs = {\n",
    "    'Question': ['Is Intekglobal an IT company?', 'Where can I apply?'],\n",
    "    'Answer':\n",
    "        ['Yes it is!', 'Please refer the our website for further information']\n",
    "}\n",
    "\n",
    "\n",
    "def mock_faq_files(tmpdirname, faqs):\n",
    "\n",
    "    faq_files = {\n",
    "        'data': path.join(tmpdirname, 'temp_faq.csv'),\n",
    "        'config': path.join(tmpdirname, 'temp_config_faq.json')\n",
    "    }\n",
    "\n",
    "    pd.DataFrame(faqs).to_csv(faq_files['data'], index=False)\n",
    "    copyfile(configs.faq.tfidf_logreg_en_faq, faq_files['config'])\n",
    "\n",
    "    updates_faq_config_file(\n",
    "        configs_path=faq_files['config'],\n",
    "        dataset_reader={'data_path': faq_files['data']}\n",
    "    )\n",
    "\n",
    "    return faq_files\n",
    "\n",
    "\n",
    "def test_get_intekglobal_responses():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        faq_files = mock_faq_files(tmpdirname, intekglobal_faqs)\n",
    "        qa_models = load_qa_models(\n",
    "            config_tfidf=faq_files['config'], download=False\n",
    "        )\n",
    "\n",
    "        responses, format_responses = get_responses(\n",
    "            pd.DataFrame(intekglobal_context),\n",
    "            'Where is Intekglobal?',\n",
    "            qa_models,\n",
    "            nb_squad_results=2\n",
    "        )\n",
    "\n",
    "        logging.debug(responses)\n",
    "        logging.debug(format_responses)\n",
    "        assert all(\n",
    "            response in ('north of mexico', 'TJ', 'Yes it is!')\n",
    "            for response in responses\n",
    "        )\n",
    "        #assert ''' Where is Intekglobal?:\n",
    "\n",
    "#0: north of mexico\n",
    "#1: Yes it is!\n",
    "#2: TJ\n",
    "#        '''.strip() == format_responses.strip()\n",
    "\n",
    "\n",
    "def test_get_responses_with_empty_context():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        min_faqs = {'Question': ['Minimum number of questions?','This is the other question?'], 'Answer': ['Two','yes']}\n",
    "        faq_files = mock_faq_files(tmpdirname, min_faqs)\n",
    "\n",
    "        qa_models = load_qa_models(\n",
    "            config_tfidf=faq_files['config'], download=False\n",
    "        )\n",
    "        empty_context = {'topic': [], 'context': []}\n",
    "\n",
    "        responses, format_responses = get_responses(\n",
    "            pd.DataFrame(empty_context),\n",
    "            'What is the minimun number of FAQ questions',\n",
    "            qa_models,\n",
    "            nb_squad_results=2\n",
    "        )\n",
    "\n",
    "        logging.debug(responses)\n",
    "        logging.debug(format_responses)\n",
    "        assert responses == ['Two']\n",
    "\n",
    "\n",
    "test_get_intekglobal_responses()\n",
    "test_get_responses_with_empty_context()\n",
    "\n",
    "del intekglobal_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_input(text):\n",
    "    '''This redundancy is needed for testing'''\n",
    "    return input(text)\n",
    "\n",
    "\n",
    "def new_answer(question, data, qa_models):\n",
    "\n",
    "    if get_input('Give a better answer [y/n]?')[0].lower() != 'y':\n",
    "        return 'no data updates..'\n",
    "\n",
    "    if get_input('Give the answer as a context [y/n]?')[0].lower() == 'y':\n",
    "        new_context = pd.DataFrame(\n",
    "            {\n",
    "                'topic': [get_input('Give context a title:\\n')],\n",
    "                'context': [get_input('Introduce the context:\\n')]\n",
    "            }\n",
    "        )\n",
    "        data['context']['df'] = data['context']['df'].append(new_context)\n",
    "        data['context']['df'].to_csv(data['context']['path'], index=False)\n",
    "\n",
    "        return 'contexts dataset updated..'\n",
    "    else:\n",
    "        new_faq = pd.DataFrame(\n",
    "            {\n",
    "                'Question': [question],\n",
    "                'Answer': [get_input('Introduce the answer:\\n')]\n",
    "            }\n",
    "        )\n",
    "        data['faq']['df'] = data['faq']['df'].append(new_faq)\n",
    "        data['faq']['df'].to_csv(data['faq']['path'], index=False)\n",
    "        qa_models['faq']['tfidf'] = train_model(\n",
    "            data['faq']['config'], download=False\n",
    "        )\n",
    "        return 'FAQ dataset and model updated..'\n",
    "\n",
    "\n",
    "def question_response(data, qa_models, num_returned_values_per_squad_model=1):\n",
    "    question = get_input('Introduce question:\\n')\n",
    "\n",
    "    _, formatted_responses = get_responses(\n",
    "        data['context']['df'], question, qa_models, nb_squad_results=2\n",
    "    )\n",
    "\n",
    "    return formatted_responses, new_answer(question, data, qa_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test FAQ dialog system's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-17 21:31:14.206 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "09:31:14 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-17 21:31:14.493 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "09:31:14 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-17 21:31:15.199 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:15 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:31:15.350 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:15 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:31:15.496 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:15 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:31:15.617 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:15 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:31:29.380 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:31:29 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:31:29 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model\n",
      "2020-06-17 21:31:47.462 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:31:47 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:31:47 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model\n",
      "2020-06-17 21:31:49.645 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:49 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:49.646 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:31:49 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:31:49.647 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:49 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:49.656 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:31:49 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:31:49.659 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:49 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:49.661 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:49 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:49.662 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:49 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:49.664 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:49 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:49.665 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:31:49 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:31:49.666 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:49 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:49.672 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:31:49 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:31:49.674 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:49 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:50.959 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:50 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:50.961 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:31:50 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:31:50.962 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:50 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:50.964 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:50 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:50.968 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:50 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:50.970 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:31:50 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:31:50.971 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:50 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:51.720 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:31:51 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:31:51.721 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:31:51 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:31:51.722 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:51 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:31:51.724 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:31:51 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:31:51.726 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:31:51 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:31:51.728 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:31:51 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:31:51.729 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:51 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:31:53 DEBUG:Responses: [list([['Intekglobal'], [0], [160.03579711914062]])\n",
      " list([['Intekglobal'], [3], [244.86245727539062]])\n",
      " list([['one of the smartest minds on the planet'], [19], [1664652.0]])]\n",
      "09:31:53 DEBUG:Top Responses: ['one of the smartest minds on the planet', 'Intekglobal']\n",
      "09:31:56 DEBUG:Responses: [list([[''], [-1], [0.0011892060283571482]])\n",
      " list([[''], [-1], [0.01691678911447525]])\n",
      " list([['one of the smartest minds on the planet, \\n                   he currently works as Intekglobal employee'], [19], [18812.87109375]])]\n",
      "09:31:56 DEBUG:Top Responses: ['one of the smartest minds on the planet, \\n                   he currently works as Intekglobal employee', '']\n",
      "09:31:56 DEBUG:  no data updates..\n",
      "09:31:56 DEBUG:  Who is Enrique Jimenez?:\n",
      "\n",
      "0: yes\n",
      "1: one of the smartest minds on the planet, \n",
      "                   he currently works as Intekglobal employee\n",
      "2: one of the smartest minds on the planet\n",
      "3: Intekglobal\n",
      "\n",
      "2020-06-17 21:31:56.677 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "09:31:56 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-17 21:31:56.938 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "09:31:56 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-17 21:31:57.451 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:57 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:31:57.596 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:57 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:31:57.721 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:57 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:31:57.824 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:31:57 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:32:12.357 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:32:12 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:32:12 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model\n",
      "2020-06-17 21:32:29.844 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:32:29 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:32:30 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model\n",
      "2020-06-17 21:32:31.947 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:31 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:31.949 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:32:31 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:32:31.950 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:31 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:31.956 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:32:31 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:32:31.959 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:31 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:31.961 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:31 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:31.962 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:31 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:31.965 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:31 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:31.967 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:32:31 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:32:31.968 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:31 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:31.975 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:32:31 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:32:31.977 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:31 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:32.768 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:32 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:32.770 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:32:32 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:32:32.771 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:32 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:32.773 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:32 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:32.775 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:32 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:32.777 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:32:32 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:32:32.777 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:32 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:33.599 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:33 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:33.600 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:32:33 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:32:33.602 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:33 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:33.604 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:33 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:33.606 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:33 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:33.607 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:32:33 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:32:33.608 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:33 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:34 DEBUG:Responses: [list([['AI research. \\n                The goal is to make an automatic pilot'], [19], [159.49786376953125]])]\n",
      "09:32:35 DEBUG:Top Responses: ['AI research. \\n                The goal is to make an automatic pilot']\n",
      "09:32:36 DEBUG:Responses: [list([['to make an automatic pilot'], [61], [129.35693359375]])]\n",
      "09:32:36 DEBUG:Top Responses: ['to make an automatic pilot']\n",
      "2020-06-17 21:32:37.401 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:37 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:37.402 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:32:37 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:32:37.403 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:37 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:37.410 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:32:37 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:32:37.412 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:37 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:37.414 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:37 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:37.415 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:37 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:37.417 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:37 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:37.420 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:32:37 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:32:37.421 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:37 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:37.428 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:32:37 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "2020-06-17 21:32:37.430 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:37 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:38.619 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:38 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:38.621 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:32:38 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:32:38.622 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:38 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:38.625 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:38 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:38.627 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:38 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:38.629 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:32:38 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:32:38.630 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:38 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:39.430 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:32:39 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:32:39.431 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:32:39 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:32:39.432 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:39 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:32:39.435 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:32:39 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:32:39.437 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:32:39 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:32:39.438 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:32:39 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:32:39.439 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:39 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:32:39 DEBUG:  FAQ dataset and model updated..\n",
      "09:32:39 DEBUG:  What is Intekglobal?:\n",
      "\n",
      "0: AI research. \n",
      "                The goal is to make an automatic pilot\n",
      "1: No, it is life on earth\n",
      "2: to make an automatic pilot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from unittest.mock import patch\n",
    "from shutil import copyfile\n",
    "from collections import defaultdict\n",
    "\n",
    "def mock_faq_files(tmpdirname, faqs, faq_dic):\n",
    "\n",
    "    faq_dic['path'] = path.join(tmpdirname, 'temp_faq.csv')\n",
    "    faq_dic['config'] = path.join(tmpdirname, 'temp_config_faq.json')\n",
    "    faq_dic['df'] = pd.DataFrame(faqs)\n",
    "    faq_dic['df'].to_csv(faq_dic['path'], index=False)\n",
    "\n",
    "    copyfile(configs.faq.tfidf_logreg_en_faq, faq_dic['config'])\n",
    "\n",
    "    updates_faq_config_file(\n",
    "        configs_path=faq_dic['config'],\n",
    "        dataset_reader={'data_path': faq_dic['path']}\n",
    "    )\n",
    "\n",
    "\n",
    "def mock_context_file(tmpdirname, contexts, context_dic):\n",
    "\n",
    "    context_dic['path'] = path.join(tmpdirname, 'temp_context.csv')\n",
    "    context_dic['df'] = pd.DataFrame(contexts)\n",
    "    context_dic['df'].to_csv(context_dic['path'], index=False)\n",
    "\n",
    "\n",
    "@patch('__main__.get_input')\n",
    "def test_context_response_with_no_updates(mock_input):\n",
    "    mock_input.side_effect = ['Who is Enrique Jimenez?', 'N']\n",
    "    data = {'context': defaultdict(str), 'faq': defaultdict(str)}\n",
    "    contexts = {\n",
    "        'context':\n",
    "            [\n",
    "                'Intekglobal has its headquarters located in TJ',\n",
    "                'In Intekglobal we care about you',\n",
    "                '''Enrique Jimenez is one of the smartest minds on the planet, \n",
    "                   he currently works as Intekglobal employee'''\n",
    "            ],\n",
    "        'topic': ['headquarters', 'mission', 'Enrique\\'s biography']\n",
    "    }\n",
    "\n",
    "    faqs = {\n",
    "        'Question':\n",
    "            ['Minimum number of questions?', 'This is the other question?'],\n",
    "        'Answer': ['Two', 'yes']\n",
    "    }\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        mock_faq_files(tmpdirname, faqs, data['faq'])\n",
    "        mock_context_file(tmpdirname, contexts, data['context'])\n",
    "\n",
    "        qa_models = load_qa_models(\n",
    "            config_tfidf=data['faq']['config'], download=False\n",
    "        )\n",
    "\n",
    "        responses, status = question_response(data, qa_models)\n",
    "        logging.debug(f'  {status}')\n",
    "        logging.debug(f'  {responses}')\n",
    "        assert 'no data updates..' == status\n",
    "        assert 'one of the smartest minds on the planet' in responses\n",
    "\n",
    "@patch('__main__.get_input')\n",
    "def test_updating_faq_dataset(mock_input):\n",
    "\n",
    "    new_answer = 'Intekglobal is one of the best companies in the world'\n",
    "    mock_input.side_effect = ['What is Intekglobal?', 'Y', 'N', new_answer]\n",
    "\n",
    "    data = {'context': defaultdict(str), 'faq': defaultdict(str)}\n",
    "    contexts = {\n",
    "        'context':\n",
    "            [\n",
    "                '''Tesla do important AI research. \n",
    "                The goal is to make an automatic pilot.\n",
    "                '''\n",
    "            ],\n",
    "        'topic': ['Tesla AI']\n",
    "    }\n",
    "\n",
    "    faqs = {\n",
    "        'Question':\n",
    "            ['Who  owns Tesla Company?', 'Is this is heaven?'],\n",
    "        'Answer': ['Elon Musk is the owner of Tesla', 'No, it is life on earth']\n",
    "    }\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        mock_faq_files(tmpdirname, faqs, data['faq'])\n",
    "        mock_context_file(tmpdirname, contexts, data['context'])\n",
    "\n",
    "        qa_models = load_qa_models(\n",
    "            config_tfidf=data['faq']['config'], download=False\n",
    "        )\n",
    "\n",
    "        responses, status = question_response(data, qa_models)\n",
    "        \n",
    "        logging.debug(f'  {status}')\n",
    "        logging.debug(f'  {responses}')\n",
    "        \n",
    "        assert 'FAQ dataset and model updated..' == status\n",
    "\n",
    "        updated_faq = pd.read_csv(data['faq']['path'])\n",
    "\n",
    "        assert updated_faq[updated_faq['Answer'] == new_answer\n",
    "                              ].shape[0] == 1\n",
    "\n",
    "        \n",
    "test_context_response_with_no_updates()\n",
    "test_updating_faq_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-17 21:32:39.562 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "09:32:39 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-17 21:32:39.836 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "09:32:39 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-17 21:32:40.483 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:32:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:32:40.622 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:32:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:32:40.776 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:32:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:32:40.871 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:32:40 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:32:55.972 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:32:55 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:32:56 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model\n",
      "2020-06-17 21:33:13.884 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:33:13 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:33:14 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model\n",
      "2020-06-17 21:33:16.97 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:16 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:16.99 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:33:16 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:33:16.101 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:16 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:16.110 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:33:16 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:33:16.113 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:16 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:16.115 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:16 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:16.117 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:16 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:16.118 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:16 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:16.120 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:33:16 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:33:16.121 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:16 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:16.127 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:33:16 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:33:16.130 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:16 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:16.910 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:16 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:16.911 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:33:16 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:33:16.912 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:16 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:16.914 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:16 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:16.916 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:16 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:16.917 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:33:16 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:33:16.918 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:16 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:17.706 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:17 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:17.708 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:33:17 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:33:17.709 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:17 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:17.711 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:17 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:17.713 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:17 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:17.715 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:33:17 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:33:17.717 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:17 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:19 DEBUG:Responses: [list([['greatest punk rock bands from all the time\\n                is the Ramones'], [11], [92.5745849609375]])]\n",
      "09:33:19 DEBUG:Top Responses: ['greatest punk rock bands from all the time\\n                is the Ramones']\n",
      "09:33:20 DEBUG:Responses: [list([['One of the greatest punk rock bands from all the time'], [0], [0.04293891042470932]])]\n",
      "09:33:20 DEBUG:Top Responses: ['One of the greatest punk rock bands from all the time']\n",
      "2020-06-17 21:33:21.989 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:21 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:21.990 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:33:21 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:33:21.991 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:21 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:21.998 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:33:21 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:33:22.0 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:22 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:22.3 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:22 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:22.5 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:22 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:22.7 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:22 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:22.8 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:33:22 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:33:22.8 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:22 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:22.15 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:33:22 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "2020-06-17 21:33:22.17 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:22 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:22.830 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:22 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:22.832 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:33:22 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:33:22.834 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:22 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:22.836 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:22 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:22.838 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:22 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:22.840 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:33:22 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:33:22.841 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:22 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:23.664 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:33:23 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:33:23.666 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:33:23 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:33:23.668 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:23 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:33:23.671 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:33:23 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:33:23.673 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:33:23 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:33:23.675 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:33:23 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:33:23.676 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:23 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:33:23 DEBUG:Responses: [list([['greatest punk rock bands from all the time\\n                is the Ramones'], [11], [92.5745849609375]])]\n",
      "09:33:23 DEBUG:Top Responses: ['greatest punk rock bands from all the time\\n                is the Ramones']\n",
      "09:33:24 DEBUG:Responses: [list([['One of the greatest punk rock bands from all the time'], [0], [0.04293891042470932]])]\n",
      "09:33:24 DEBUG:Top Responses: ['One of the greatest punk rock bands from all the time']\n",
      "09:33:24 INFO:Old response:\n",
      " What is Intekglobal?:\n",
      "\n",
      "0: No, it is life on earth\n",
      "1: One of the greatest punk rock bands from all the time\n",
      "2: greatest punk rock bands from all the time\n",
      "                is the Ramones\n",
      "\n",
      "09:33:24 INFO:New response:\n",
      "What is Intekglobal?:\n",
      "\n",
      "0: One of the greatest punk rock bands from all the time\n",
      "1: Intekglobal is one of the best companies in the world\n",
      "2: greatest punk rock bands from all the time\n",
      "                is the Ramones\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tests\n",
    "import tempfile\n",
    "from unittest.mock import patch\n",
    "from shutil import copyfile\n",
    "from collections import defaultdict\n",
    "\n",
    "def mock_faq_files(tmpdirname, faqs, faq_dic):\n",
    "\n",
    "    faq_dic['path'] = path.join(tmpdirname, 'temp_faq.csv')\n",
    "    faq_dic['config'] = path.join(tmpdirname, 'temp_config_faq.json')\n",
    "    faq_dic['df'] = pd.DataFrame(faqs)\n",
    "    faq_dic['df'].to_csv(faq_dic['path'], index=False)\n",
    "\n",
    "    copyfile(configs.faq.tfidf_logreg_en_faq, faq_dic['config'])\n",
    "\n",
    "    updates_faq_config_file(\n",
    "        configs_path=faq_dic['config'],\n",
    "        dataset_reader={'data_path': faq_dic['path']}\n",
    "    )\n",
    "\n",
    "\n",
    "def mock_context_file(tmpdirname, contexts, context_dic):\n",
    "\n",
    "    context_dic['path'] = path.join(tmpdirname, 'temp_context.csv')\n",
    "    context_dic['df'] = pd.DataFrame(contexts)\n",
    "    context_dic['df'].to_csv(context_dic['path'], index=False)\n",
    "\n",
    "@patch('__main__.get_input')\n",
    "def test_updated_faq_response(mock_input):\n",
    "\n",
    "    new_answer = 'Intekglobal is one of the best companies in the world'\n",
    "    question = 'What is Intekglobal?'\n",
    "    mock_input.side_effect = [question, 'Y', 'N', new_answer, question, 'N']\n",
    "\n",
    "    data = {'context': defaultdict(str), 'faq': defaultdict(str)}\n",
    "    contexts = {\n",
    "        'context':\n",
    "            [\n",
    "                '''One of the greatest punk rock bands from all the time\n",
    "                is the Ramones.\n",
    "                '''\n",
    "            ],\n",
    "        'topic': ['Ramones']\n",
    "    }\n",
    "\n",
    "    faqs = {\n",
    "        'Question':\n",
    "            ['Who was the leading vocal artist of the Ramones?', 'Is this is heaven?'],\n",
    "        'Answer': ['Joey Ramone', 'No, it is life on earth']\n",
    "    }\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        mock_faq_files(tmpdirname, faqs, data['faq'])\n",
    "        mock_context_file(tmpdirname, contexts, data['context'])\n",
    "\n",
    "        qa_models = load_qa_models(\n",
    "            config_tfidf=data['faq']['config'], download=False\n",
    "        )\n",
    "        old_responses, old_status = question_response(data, qa_models)\n",
    "        new_responses, new_status = question_response(data, qa_models)\n",
    "\n",
    "        logging.info(f'Old response:\\n {old_responses}')\n",
    "        logging.info(f'New response:\\n{new_responses}')\n",
    "        \n",
    "        new_answer not in old_responses\n",
    "        new_answer in new_responses\n",
    "\n",
    "test_updated_faq_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Contex Dialog System's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-17 21:33:24.843 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "09:33:24 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl\n",
      "2020-06-17 21:33:25.133 INFO in 'deeppavlov.models.preprocessors.squad_preprocessor'['squad_preprocessor'] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "09:33:25 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl\n",
      "2020-06-17 21:33:25.649 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:33:25 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:33:25.859 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:33:25 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:33:26.19 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:33:26 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:33:26.137 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 615: \n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "09:33:26 INFO:\n",
      "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. \n",
      "2020-06-17 21:33:39.395 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:33:39 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]\n",
      "09:33:39 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model\n",
      "2020-06-17 21:33:58.24 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:33:58 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]\n",
      "09:33:58 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model\n",
      "2020-06-17 21:34:00.171 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:34:00 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:34:00.173 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:34:00 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:34:00.173 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:34:00 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:34:00.181 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "09:34:00 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
      "2020-06-17 21:34:00.184 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:34:00 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:34:00.187 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:34:00 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:34:00.189 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:34:00 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:34:00.191 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:34:00 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:34:00.192 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:34:00 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:34:00.193 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:34:00 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:34:00.200 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "09:34:00 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2020-06-17 21:34:00.203 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:34:00 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:34:00.963 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:34:00 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:34:00.964 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:34:00 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:34:00.966 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:34:00 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:34:00.968 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:34:00 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:34:00.970 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:34:00 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:34:00.971 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:34:00 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:34:00.972 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:34:00 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:34:02.233 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "09:34:02 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
      "2020-06-17 21:34:02.234 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "09:34:02 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
      "2020-06-17 21:34:02.235 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:34:02 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "2020-06-17 21:34:02.237 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "09:34:02 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
      "2020-06-17 21:34:02.239 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "09:34:02 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
      "2020-06-17 21:34:02.240 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "09:34:02 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
      "2020-06-17 21:34:02.241 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:34:02 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
      "09:34:03 DEBUG:Responses: [list([['Intekglobal'], [0], [31.67441177368164]])]\n",
      "09:34:03 DEBUG:Top Responses: ['Intekglobal']\n",
      "09:34:05 DEBUG:Responses: [list([[''], [-1], [0.005045291036367416]])]\n",
      "09:34:05 DEBUG:Top Responses: ['']\n",
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "09:34:05 DEBUG:Responses: [list([['Intekglobal'], [0], [31.67441177368164]])\n",
      " list([['an important tool for simulating intelligent conversations with humans'], [15], [18000700.0]])]\n",
      "09:34:05 DEBUG:Top Responses: ['an important tool for simulating intelligent conversations with humans', 'Intekglobal']\n",
      "09:34:07 DEBUG:Responses: [list([[''], [-1], [0.005045291036367416]])\n",
      " list([['an important tool for simulating intelligent conversations with humans'], [15], [2104.719482421875]])]\n",
      "09:34:07 DEBUG:Top Responses: ['an important tool for simulating intelligent conversations with humans', '']\n",
      "09:34:07 INFO:Old status: contexts dataset updated..\n",
      "09:34:07 INFO:Old response:\n",
      " What is a Chatbot?:\n",
      "\n",
      "0: yes\n",
      "1: Intekglobal\n",
      "\n",
      "09:34:07 INFO:New response:\n",
      "What is a Chatbot?:\n",
      "\n",
      "0: an important tool for simulating intelligent conversations with humans\n",
      "1: yes\n",
      "2: Intekglobal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from unittest.mock import patch\n",
    "from shutil import copyfile\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def mock_faq_files(tmpdirname, faqs, faq_dic):\n",
    "\n",
    "    faq_dic['path'] = path.join(tmpdirname, 'temp_faq.csv')\n",
    "    faq_dic['config'] = path.join(tmpdirname, 'temp_config_faq.json')\n",
    "    faq_dic['df'] = pd.DataFrame(faqs)\n",
    "    faq_dic['df'].to_csv(faq_dic['path'], index=False)\n",
    "\n",
    "    copyfile(configs.faq.tfidf_logreg_en_faq, faq_dic['config'])\n",
    "\n",
    "    updates_faq_config_file(\n",
    "        configs_path=faq_dic['config'],\n",
    "        dataset_reader={'data_path': faq_dic['path']}\n",
    "    )\n",
    "\n",
    "\n",
    "def mock_context_file(tmpdirname, contexts, context_dic):\n",
    "\n",
    "    context_dic['path'] = path.join(tmpdirname, 'temp_context.csv')\n",
    "    context_dic['df'] = pd.DataFrame(contexts)\n",
    "    context_dic['df'].to_csv(context_dic['path'], index=False)\n",
    "\n",
    "\n",
    "@patch('__main__.get_input')\n",
    "def test_updated_context_response(mock_input):\n",
    "    data = {'context': defaultdict(str), 'faq': defaultdict(str)}\n",
    "\n",
    "    contexts = {\n",
    "        'context': ['Intekglobal has its headquarters located in TJ', ],\n",
    "        'topic': ['headquarters']\n",
    "    }\n",
    "\n",
    "    faqs = {\n",
    "        'Question':\n",
    "            ['Minimum number of questions?', 'This is the other question?'],\n",
    "        'Answer': ['Two', 'yes']\n",
    "    }\n",
    "\n",
    "    question = 'What is a Chatbot?'\n",
    "    new_topic = 'AI Tool & Chatbot Development'\n",
    "    new_context = '''\n",
    "\n",
    "A chatbot is an important tool for simulating intelligent conversations with humans.\n",
    "Intekglobal chatbots efficiently live message on platforms such as Facebook Messenger, \n",
    "Slack, and Telegram. Assisting consumers with a variety of purposes and industries. \n",
    "\n",
    "But chatbots are more than just a cool technology advancement. They actually transform the user experience.\n",
    "People want simple and convenient interactions with interface and products.\n",
    "\n",
    "'''\n",
    "\n",
    "    mock_input.side_effect = [\n",
    "        question, 'YES', 'yes', new_topic, new_context, question, 'N'\n",
    "    ]\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "\n",
    "        mock_faq_files(tmpdirname, faqs, data['faq'])\n",
    "        mock_context_file(tmpdirname, contexts, data['context'])\n",
    "\n",
    "        qa_models = load_qa_models(\n",
    "            config_tfidf=data['faq']['config'], download=False\n",
    "        )\n",
    "\n",
    "        old_responses, old_status = question_response(data, qa_models)\n",
    "        new_responses, new_status = question_response(data, qa_models)\n",
    "\n",
    "        logging.info(f'Old status: {old_status}')\n",
    "        logging.info(f'Old response:\\n {old_responses}')\n",
    "        logging.info(f'New response:\\n{new_responses}')\n",
    "\n",
    "        updated_context = pd.read_csv(data['context']['path'])\n",
    "\n",
    "        assert updated_context[updated_context['context'] == new_context\n",
    "                              ].shape[0] == 1\n",
    "\n",
    "        assert updated_context[updated_context['topic'] == new_topic\n",
    "                              ].shape[0] == 1\n",
    "\n",
    "        assert 'an important tool for simulating intelligent conversations with humans' not in old_responses\n",
    "        assert 'an important tool for simulating intelligent conversations with humans' in new_responses\n",
    "\n",
    "\n",
    "test_updated_context_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def set_minimal_faq_questions(data):\n",
    "    if data['df'].shape[0] > 1:\n",
    "        return\n",
    "    minimal_questions = [\n",
    "        'Is this the Intekglobal Dialog System?',\n",
    "        'What is the purpose of these two automated questions?'\n",
    "    ]\n",
    "    minimal_answers = [\n",
    "        'This is the Intekglobal Dialog System', 'To populate the FAQ data file'\n",
    "    ]\n",
    "    minimal_faqs_df = pd.DataFrame(\n",
    "        {\n",
    "            'Question': minimal_questions,\n",
    "            'Answer': minimal_answers\n",
    "        }\n",
    "    )\n",
    "    data['df'] = pd.concat([data['df'], minimal_faqs_df])\n",
    "    data['df'].to_csv(data['path'], index=False)\n",
    "    logging.info(f' File created at {data[\"path\"]}')\n",
    "\n",
    "\n",
    "def set_minimal_contexts(data):\n",
    "    if data['df'].shape[0] > 0:\n",
    "        return\n",
    "\n",
    "    minimal_context_df = pd.DataFrame({'topic': [], 'context': []})\n",
    "    data['df'] = minimal_context_df\n",
    "    data['df'].to_csv(data['path'], index=False)\n",
    "\n",
    "    logging.info(f' File created at {data[\"path\"]}')\n",
    "\n",
    "\n",
    "def set_data_dict(file, data, question_type, data_dir):\n",
    "\n",
    "    data['path'] = file if file is not None else path.join(\n",
    "        data_dir, question_type + '_data.csv'\n",
    "    )\n",
    "\n",
    "    data['df'] = pd.read_csv(data['path']) if path.isfile(data['path']\n",
    "                                                         ) else pd.DataFrame()\n",
    "\n",
    "    if question_type == 'faq':\n",
    "        set_minimal_faq_questions(data)\n",
    "    if question_type == 'context':\n",
    "        set_minimal_contexts(data)\n",
    "\n",
    "\n",
    "def load_and_prepare_data(context_data_file, faq_data_file, data, configs_faq):\n",
    "\n",
    "    PARENT_DIR = popen('dirname $PWD').read().strip()\n",
    "\n",
    "    if faq_data_file or context_data_file is None:\n",
    "        DATA_DIR = path.join(PARENT_DIR, 'data')\n",
    "\n",
    "        if not path.isdir(DATA_DIR):\n",
    "            mkdir(DATA_DIR)\n",
    "            logging.info(f'Data directory created at {DATA_DIR}')\n",
    "\n",
    "    if configs_faq is None:\n",
    "        configs_faq = path.join(PARENT_DIR, 'config_faq.json')\n",
    "        copyfile(configs.faq.tfidf_logreg_en_faq, configs_faq)\n",
    "\n",
    "    data['faq']['config'] = configs_faq\n",
    "\n",
    "    set_data_dict(\n",
    "        file=faq_data_file,\n",
    "        data=data['faq'],\n",
    "        question_type='faq',\n",
    "        data_dir=DATA_DIR\n",
    "    )\n",
    "    set_data_dict(\n",
    "        file=context_data_file,\n",
    "        data=data['context'],\n",
    "        question_type='context',\n",
    "        data_dir=DATA_DIR\n",
    "    )\n",
    "\n",
    "    updates_faq_config_file(\n",
    "        configs_path=configs_faq,\n",
    "        dataset_reader={'data_path': data['faq']['path']}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:34:07 INFO: File created at /tmp/tmpjibn7q10/tmp_data.csv\n",
      "09:34:07 INFO: File created at /tmp/tmp9pp0sidn/tmp_data.csv\n",
      "09:34:07 INFO: File created at /tmp/tmp6d4_0uj3/context_data.csv\n",
      "09:34:07 DEBUG:{'context': defaultdict(<class 'str'>, {'path': '/tmp/tmp6d4_0uj3/context_data.csv', 'df': Empty DataFrame\n",
      "Columns: [topic, context]\n",
      "Index: []})}\n",
      "09:34:07 INFO:Data directory created at /tmp/tmpwco3b_z4/data\n",
      "09:34:07 INFO: File created at /tmp/tmpwco3b_z4/data/faq_data.csv\n",
      "09:34:07 INFO: File created at /tmp/tmpwco3b_z4/data/context_data.csv\n"
     ]
    }
   ],
   "source": [
    "#tests\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "from shutil import rmtree\n",
    "from unittest.mock import patch\n",
    "from let_me_answer_for_you.dialog_system import updates_faq_config_file\n",
    "\n",
    "\n",
    "def test_set_minimal_faqs_with_more_than_one_question():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        data_file = path.join(tmpdirname, 'tmp_data.csv')\n",
    "        questions = ['a?', 'b?']\n",
    "        answers = ['a', 'b']\n",
    "        df = pd.DataFrame({'Question': questions, 'Answer': answers})\n",
    "        df.to_csv(data_file, index=False)\n",
    "        data = {'df': df, 'path': data_file}\n",
    "        set_minimal_faq_questions(data)\n",
    "\n",
    "        assert data['df'].shape[0] == 2\n",
    "\n",
    "\n",
    "def test_set_minimal_faqs_with_less_than_two_questions():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        data_file = path.join(tmpdirname, 'tmp_data.csv')\n",
    "        questions = ['a?']\n",
    "        answers = ['a']\n",
    "        df = pd.DataFrame({'Question': questions, 'Answer': answers})\n",
    "        df.to_csv(data_file, index=False)\n",
    "        data = {'df': df, 'path': data_file}\n",
    "\n",
    "        assert data['df'].shape[0] == 1\n",
    "\n",
    "        set_minimal_faq_questions(data)\n",
    "\n",
    "        assert data['df'].shape[0] == 3\n",
    "        assert any(\n",
    "            data['df'].Question == 'Is this the Intekglobal Dialog System?'\n",
    "        )\n",
    "\n",
    "\n",
    "def test_set_minimal_contexts():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        data_file = path.join(tmpdirname, 'tmp_data.csv')\n",
    "        data = {'df': pd.DataFrame(), 'path': data_file}\n",
    "        set_minimal_contexts(data)\n",
    "        assert path.isfile(data['path'])\n",
    "        assert all(data['df'].columns == ['topic', 'context'])\n",
    "\n",
    "\n",
    "def test_set_data_dict_no_file():\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        data = {'context': defaultdict(str)}\n",
    "        set_data_dict(\n",
    "            file=None,\n",
    "            data=data['context'],\n",
    "            data_dir=tmpdirname,\n",
    "            question_type='context'\n",
    "        )\n",
    "        logging.debug(data)\n",
    "        assert path.isfile(data['context']['path'])\n",
    "\n",
    "\n",
    "@patch('__main__.popen')\n",
    "def test_load_and_prepare_data(mock_popen):\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        mock_popen(\"dirname $PWD\").read().strip.side_effect = [tmpdirname]\n",
    "        #tmp_config_file = path.join(tmpdirname, 'tmp_file.json')\n",
    "        #copyfile(configs.faq.tfidf_logreg_en_faq, tmp_config_file)\n",
    "        data = {'context': defaultdict(str), 'faq': defaultdict(str)}\n",
    "\n",
    "        load_and_prepare_data(\n",
    "            context_data_file=None,\n",
    "            faq_data_file=None,\n",
    "            data=data,\n",
    "            configs_faq=None\n",
    "        )\n",
    "        data_dir = path.join(tmpdirname, 'data')\n",
    "        config_file = path.join(tmpdirname,'config_faq.json')\n",
    "        assert path.isdir(data_dir)\n",
    "        assert path.isfile(config_file)\n",
    "\n",
    "\n",
    "test_set_minimal_faqs_with_more_than_one_question()\n",
    "test_set_minimal_faqs_with_less_than_two_questions()\n",
    "test_set_minimal_contexts()\n",
    "test_set_data_dict_no_file()\n",
    "test_load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dialog_system(context_data_file=None, faq_data_file=None, configs_faq=None):\n",
    "    '''\n",
    "     Main Dialog System\n",
    "    '''\n",
    "    run_shell_installs()\n",
    "\n",
    "    data = {'context': defaultdict(str), 'faq': defaultdict(str)}\n",
    "\n",
    "    load_and_prepare_data(\n",
    "        context_data_file=context_data_file,\n",
    "        faq_data_file=faq_data_file,\n",
    "        configs_faq=configs_faq,\n",
    "        data=data\n",
    "    )\n",
    "\n",
    "    qa_models = load_qa_models(configs_tfidf=data['faq']['config'])\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            question_response(data=data, qa_models=qa_models)\n",
    "        except (KeyboardInterrupt, EOFError, SystemExit):\n",
    "            logging.debug('Goodbye!')\n",
    "            return 'Goodbye!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:34:07 DEBUG:Goodbye!\n",
      "09:34:07 DEBUG:Goodbye!\n",
      "09:34:07 DEBUG:Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# test  dialog_system()\n",
    "\n",
    "from unittest.mock import patch\n",
    "from let_me_answer_for_you.dialog_system import load_qa_models\n",
    "from let_me_answer_for_you.dialog_system import question_response\n",
    "\n",
    "@patch('__main__.run_shell_installs')\n",
    "@patch('__main__.load_qa_models')\n",
    "@patch('__main__.load_and_prepare_data')\n",
    "@patch('__main__.question_response')\n",
    "def test_main_keyboard_interrupt(\n",
    "    mock_question_response,\n",
    "    mock_pd_read_csv,\n",
    "    mock_load_qa_models,\n",
    "    mock_run_shell_installs,\n",
    "):\n",
    "    mock_question_response.side_effect = [\n",
    "        KeyboardInterrupt(), EOFError(),\n",
    "        SystemExit()\n",
    "    ]\n",
    "    assert 'Goodbye!' == dialog_system()\n",
    "    assert 'Goodbye!' == dialog_system()\n",
    "    assert 'Goodbye!' == dialog_system()\n",
    "\n",
    "\n",
    "test_main_keyboard_interrupt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
