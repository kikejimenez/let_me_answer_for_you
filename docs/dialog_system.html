---

title: Dialog System

keywords: fastai
sidebar: home_sidebar

summary: "Question Answering Automated Dialog System"
description: "Question Answering Automated Dialog System"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_dialog_system.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>07:01:05 INFO:Hello! Welcome to our automated dialog system!
07:01:05 DEBUG:test: for Debug?
07:01:05 ERROR: Error Log Active 
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>04:57:57 INFO:Hello! Welcome to our automated dialog system!
04:57:57 DEBUG:test: for Debug?
04:57:57 ERROR: Error Log Active 
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="run_shell_installs" class="doc_header"><code>run_shell_installs</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L25" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>run_shell_installs</code>()</p>
</blockquote>
<p>Run install commands</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">run_shell_installs</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>04:57:57 DEBUG: pip install deeppavlov
04:57:59 DEBUG:Requirement already satisfied: deeppavlov in /opt/conda/lib/python3.7/site-packages (0.10.0)
Requirement already satisfied: overrides==2.7.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.7.0)
Requirement already satisfied: pytz==2019.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2019.1)
Requirement already satisfied: pymorphy2-dicts-ru in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.4.404381.4453942)
Requirement already satisfied: uvicorn==0.11.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.11.1)
Requirement already satisfied: nltk==3.4.5 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (3.4.5)
Requirement already satisfied: pandas==0.25.3 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.25.3)
Requirement already satisfied: tqdm==4.41.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (4.41.1)
Requirement already satisfied: Cython==0.29.14 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.29.14)
Requirement already satisfied: pyopenssl==19.1.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (19.1.0)
Requirement already satisfied: requests==2.22.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.22.0)
Requirement already satisfied: h5py==2.10.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (2.10.0)
Requirement already satisfied: scikit-learn==0.21.2 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.21.2)
Requirement already satisfied: fastapi==0.47.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.47.1)
Requirement already satisfied: rusenttokenize==0.0.5 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.0.5)
Requirement already satisfied: sacremoses==0.0.35 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.0.35)
Requirement already satisfied: ruamel.yaml==0.15.100 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.15.100)
Requirement already satisfied: aio-pika==6.4.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (6.4.1)
Requirement already satisfied: pydantic==1.3 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.3)
Requirement already satisfied: pymorphy2==0.8 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (0.8)
Requirement already satisfied: pytelegrambotapi==3.6.7 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (3.6.7)
Requirement already satisfied: scipy==1.4.1 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.4.1)
Requirement already satisfied: numpy==1.18.0 in /opt/conda/lib/python3.7/site-packages (from deeppavlov) (1.18.0)
Requirement already satisfied: uvloop&gt;=0.14.0; sys_platform != &#34;win32&#34; and sys_platform != &#34;cygwin&#34; and platform_python_implementation != &#34;pypy&#34; in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1-&gt;deeppavlov) (0.14.0)
Requirement already satisfied: h11&lt;0.10,&gt;=0.8 in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1-&gt;deeppavlov) (0.9.0)
Requirement already satisfied: httptools==0.0.13; sys_platform != &#34;win32&#34; and sys_platform != &#34;cygwin&#34; and platform_python_implementation != &#34;pypy&#34; in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1-&gt;deeppavlov) (0.0.13)
Requirement already satisfied: click==7.* in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1-&gt;deeppavlov) (7.1.2)
Requirement already satisfied: websockets==8.* in /opt/conda/lib/python3.7/site-packages (from uvicorn==0.11.1-&gt;deeppavlov) (8.1)
Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk==3.4.5-&gt;deeppavlov) (1.14.0)
Requirement already satisfied: python-dateutil&gt;=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3-&gt;deeppavlov) (2.8.1)
Requirement already satisfied: cryptography&gt;=2.8 in /opt/conda/lib/python3.7/site-packages (from pyopenssl==19.1.0-&gt;deeppavlov) (2.8)
Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0-&gt;deeppavlov) (2.8)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0-&gt;deeppavlov) (2019.11.28)
Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0-&gt;deeppavlov) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests==2.22.0-&gt;deeppavlov) (1.25.7)
Requirement already satisfied: joblib&gt;=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.21.2-&gt;deeppavlov) (0.15.1)
Requirement already satisfied: starlette&lt;=0.12.9,&gt;=0.12.9 in /opt/conda/lib/python3.7/site-packages (from fastapi==0.47.1-&gt;deeppavlov) (0.12.9)
Requirement already satisfied: yarl in /opt/conda/lib/python3.7/site-packages (from aio-pika==6.4.1-&gt;deeppavlov) (1.4.2)
Requirement already satisfied: aiormq&lt;4,&gt;=3.2.0 in /opt/conda/lib/python3.7/site-packages (from aio-pika==6.4.1-&gt;deeppavlov) (3.2.2)
Requirement already satisfied: pymorphy2-dicts&lt;3.0,&gt;=2.4 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8-&gt;deeppavlov) (2.4.393442.3710985)
Requirement already satisfied: docopt&gt;=0.6 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8-&gt;deeppavlov) (0.6.2)
Requirement already satisfied: dawg-python&gt;=0.7 in /opt/conda/lib/python3.7/site-packages (from pymorphy2==0.8-&gt;deeppavlov) (0.7.2)
Requirement already satisfied: cffi!=1.11.3,&gt;=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography&gt;=2.8-&gt;pyopenssl==19.1.0-&gt;deeppavlov) (1.14.0)
Requirement already satisfied: multidict&gt;=4.0 in /opt/conda/lib/python3.7/site-packages (from yarl-&gt;aio-pika==6.4.1-&gt;deeppavlov) (4.7.6)
Requirement already satisfied: pamqp==2.3.0 in /opt/conda/lib/python3.7/site-packages (from aiormq&lt;4,&gt;=3.2.0-&gt;aio-pika==6.4.1-&gt;deeppavlov) (2.3.0)
Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,&gt;=1.8-&gt;cryptography&gt;=2.8-&gt;pyopenssl==19.1.0-&gt;deeppavlov) (2.20)

04:57:59 DEBUG: python -m deeppavlov install squad
04:58:47 DEBUG:Collecting tensorflow==1.15.2
  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)
Requirement already satisfied: keras-preprocessing&gt;=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.2)
Requirement already satisfied: wheel&gt;=0.26; python_version &gt;= &#34;3&#34; in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.34.2)
Requirement already satisfied: protobuf&gt;=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.12.2)
Requirement already satisfied: tensorboard&lt;1.16.0,&gt;=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.0)
Requirement already satisfied: six&gt;=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.14.0)
Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.1)
Requirement already satisfied: google-pasta&gt;=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.0)
Requirement already satisfied: keras-applications&gt;=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.0.8)
Requirement already satisfied: termcolor&gt;=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.0)
Requirement already satisfied: wrapt&gt;=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.12.1)
Requirement already satisfied: astor&gt;=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.8.1)
Requirement already satisfied: grpcio&gt;=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.29.0)
Requirement already satisfied: numpy&lt;2.0,&gt;=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.18.0)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.2.1)
Requirement already satisfied: absl-py&gt;=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.9.0)
Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.2)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf&gt;=3.6.1-&gt;tensorflow==1.15.2) (46.0.0.post20200311)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (3.2.2)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (1.0.1)
Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications&gt;=1.0.8-&gt;tensorflow==1.15.2) (2.10.0)
Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /opt/conda/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (1.5.0)
Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;markdown&gt;=2.6.8-&gt;tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (3.1.0)
Installing collected packages: tensorflow
  Attempting uninstall: tensorflow
    Found existing installation: tensorflow 1.15.3
    Uninstalling tensorflow-1.15.3:
      Successfully uninstalled tensorflow-1.15.3
Successfully installed tensorflow-1.15.2

04:58:47 DEBUG: python -m deeppavlov install squad_bert
04:58:54 DEBUG:Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu
  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-6561hb0i
Building wheels for collected packages: bert-dp
  Building wheel for bert-dp (setup.py): started
  Building wheel for bert-dp (setup.py): finished with status &#39;done&#39;
  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23580 sha256=18f9d847e6896f408cde9be2de1cd2037499c7ad19e46629fe76281f0d51191f
  Stored in directory: /tmp/pip-ephem-wheel-cache-bxa7p9fk/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb
Successfully built bert-dp
Installing collected packages: bert-dp
Successfully installed bert-dp-1.0
Requirement already satisfied: tensorflow==1.15.2 in /opt/conda/lib/python3.7/site-packages (1.15.2)
Requirement already satisfied: protobuf&gt;=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.12.2)
Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.2)
Requirement already satisfied: wheel&gt;=0.26; python_version &gt;= &#34;3&#34; in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.34.2)
Requirement already satisfied: astor&gt;=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.8.1)
Requirement already satisfied: six&gt;=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.14.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.0)
Requirement already satisfied: grpcio&gt;=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.29.0)
Requirement already satisfied: google-pasta&gt;=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.0)
Requirement already satisfied: absl-py&gt;=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.9.0)
Requirement already satisfied: numpy&lt;2.0,&gt;=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.18.0)
Requirement already satisfied: keras-preprocessing&gt;=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.2)
Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.1)
Requirement already satisfied: keras-applications&gt;=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.0.8)
Requirement already satisfied: wrapt&gt;=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.12.1)
Requirement already satisfied: tensorboard&lt;1.16.0,&gt;=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.0)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.2.1)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf&gt;=3.6.1-&gt;tensorflow==1.15.2) (46.0.0.post20200311)
Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications&gt;=1.0.8-&gt;tensorflow==1.15.2) (2.10.0)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (1.0.1)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (3.2.2)
Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /opt/conda/lib/python3.7/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (1.5.0)
Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;markdown&gt;=2.6.8-&gt;tensorboard&lt;1.16.0,&gt;=1.15.0-&gt;tensorflow==1.15.2) (3.1.0)

04:58:54 DEBUG: python -m deeppavlov install fasttext_avg_autofaq
04:59:36 DEBUG:Collecting fasttext==0.9.1
  Downloading fasttext-0.9.1.tar.gz (57 kB)
Requirement already satisfied: pybind11&gt;=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (2.5.0)
Requirement already satisfied: setuptools&gt;=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (46.0.0.post20200311)
Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (1.18.0)
Building wheels for collected packages: fasttext
  Building wheel for fasttext (setup.py): started
  Building wheel for fasttext (setup.py): finished with status &#39;done&#39;
  Created wheel for fasttext: filename=fasttext-0.9.1-cp37-cp37m-linux_x86_64.whl size=2481971 sha256=e18bf0ce7735f3a0c3fca1adeaf98a4434c0c9d1e5ddc719cafcbc01a7151de1
  Stored in directory: /home/jovyan/.cache/pip/wheels/b2/5b/4b/9c582c778bb93aaad8fc855d5e79f49eae34f59e363a22c422
Successfully built fasttext
Installing collected packages: fasttext
Successfully installed fasttext-0.9.1

04:59:36 DEBUG: python -m deeppavlov install fasttext_tfidf_autofaq
04:59:38 DEBUG:Requirement already satisfied: fasttext==0.9.1 in /opt/conda/lib/python3.7/site-packages (0.9.1)
Requirement already satisfied: pybind11&gt;=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (2.5.0)
Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (1.18.0)
Requirement already satisfied: setuptools&gt;=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext==0.9.1) (46.0.0.post20200311)

04:59:38 DEBUG: python -m deeppavlov install tfidf_autofaq
04:59:39 DEBUG:
04:59:39 DEBUG: python -m deeppavlov install tfidf_logreg_autofaq 
04:59:40 DEBUG:
04:59:40 DEBUG: python -m deeppavlov install tfidf_logreg_en_faq
04:59:56 DEBUG:Collecting spacy==2.2.3
  Downloading spacy-2.2.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)
Collecting catalogue&lt;1.1.0,&gt;=0.0.7
  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)
Requirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (2.22.0)
Requirement already satisfied: numpy&gt;=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (1.18.0)
Collecting blis&lt;0.5.0,&gt;=0.4.0
  Downloading blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy==2.2.3) (46.0.0.post20200311)
Collecting plac&lt;1.2.0,&gt;=0.9.6
  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)
Collecting cymem&lt;2.1.0,&gt;=2.0.2
  Downloading cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl (32 kB)
Collecting murmurhash&lt;1.1.0,&gt;=0.28.0
  Downloading murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (19 kB)
Collecting wasabi&lt;1.1.0,&gt;=0.4.0
  Downloading wasabi-0.6.0-py3-none-any.whl (20 kB)
Collecting srsly&lt;1.1.0,&gt;=0.1.0
  Downloading srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185 kB)
Collecting thinc&lt;7.4.0,&gt;=7.3.0
  Downloading thinc-7.3.1-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)
Collecting preshed&lt;3.1.0,&gt;=3.0.2
  Downloading preshed-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (118 kB)
Requirement already satisfied: importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34; in /opt/conda/lib/python3.7/site-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy==2.2.3) (1.5.0)
Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==2.2.3) (3.0.4)
Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==2.2.3) (2.8)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==2.2.3) (2019.11.28)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==2.2.3) (1.25.7)
Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc&lt;7.4.0,&gt;=7.3.0-&gt;spacy==2.2.3) (4.41.1)
Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34;-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy==2.2.3) (3.1.0)
Installing collected packages: catalogue, blis, plac, cymem, murmurhash, wasabi, srsly, preshed, thinc, spacy
Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.2.3 srsly-1.0.2 thinc-7.3.1 wasabi-0.6.0
Collecting en_core_web_sm==2.2.5
  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)
Requirement already satisfied: spacy&gt;=2.2.2 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.3)
Requirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (2.22.0)
Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (1.1.3)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (1.0.2)
Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (0.6.0)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (3.0.2)
Requirement already satisfied: numpy&gt;=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (1.18.0)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (2.0.3)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (46.0.0.post20200311)
Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (1.0.0)
Requirement already satisfied: srsly&lt;1.1.0,&gt;=0.1.0 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (1.0.2)
Requirement already satisfied: thinc&lt;7.4.0,&gt;=7.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (7.3.1)
Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (0.4.1)
Requirement already satisfied: chardet&lt;3.1.0,&gt;=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (2019.11.28)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (1.25.7)
Requirement already satisfied: idna&lt;2.9,&gt;=2.5 in /opt/conda/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (2.8)
Requirement already satisfied: importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34; in /opt/conda/lib/python3.7/site-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (1.5.0)
Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc&lt;7.4.0,&gt;=7.3.0-&gt;spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (4.41.1)
Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata&gt;=0.20; python_version &lt; &#34;3.8&#34;-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.2.2-&gt;en_core_web_sm==2.2.5) (3.1.0)
Building wheels for collected packages: en-core-web-sm
  Building wheel for en-core-web-sm (setup.py): started
  Building wheel for en-core-web-sm (setup.py): finished with status &#39;done&#39;
  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011738 sha256=bb9526fa914603f963da08cf6b222f97260d35caa36a01f55476d3dee159f204
  Stored in directory: /home/jovyan/.cache/pip/wheels/51/19/da/a3885266a3c241aff0ad2eb674ae058fd34a4870fef1c0a5a0
Successfully built en-core-web-sm
Installing collected packages: en-core-web-sm
Successfully installed en-core-web-sm-2.2.5

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="action_over_list_f" class="doc_header"><code>action_over_list_f</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L44" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>action_over_list_f</code>(<strong><code>arr</code></strong>, <strong><code>v</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="replacement_f" class="doc_header"><code>replacement_f</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L54" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>replacement_f</code>(<strong><code>model_config</code></strong>, <strong>**<code>args</code></strong>)</p>
</blockquote>
<p>Replaces the model config dictionary with new values</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test action_over_list_f</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">randint</span>


<span class="k">def</span> <span class="nf">gen_list_keys_for_tests</span><span class="p">():</span>

    <span class="n">str_n</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span><span class="si">:</span><span class="s1">1</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="n">gen_dict_list</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">),</span>
        <span class="s1">&#39;key1&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;v1&#39;</span><span class="p">),</span>
        <span class="s1">&#39;key2&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">),</span>
        <span class="s1">&#39;key3&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;v3&#39;</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">pipe_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">gen_dict_list</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))]</span>

    <span class="n">rand_id</span> <span class="o">=</span> <span class="n">pipe_list</span><span class="p">[</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipe_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
    <span class="n">rand_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;key</span><span class="si">{</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span> 

    <span class="n">new_rand_val</span> <span class="o">=</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;new&#39;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;chains&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;pipe&#39;</span><span class="p">:</span> <span class="p">[{</span>
                <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">rand_id</span>
            <span class="p">},</span> <span class="p">{</span>
               <span class="n">rand_key</span> <span class="p">:</span> <span class="n">new_rand_val</span>
            <span class="p">}]</span>
        <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">pipe_list</span><span class="p">,</span> <span class="n">rand_id</span><span class="p">,</span> <span class="n">rand_key</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">new_rand_val</span>


<span class="k">def</span> <span class="nf">test_action_over_list_f</span><span class="p">():</span>

    <span class="n">pipe_list</span><span class="p">,</span> <span class="n">rand_id</span><span class="p">,</span> <span class="n">rand_key</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">new_rand_val</span> <span class="o">=</span> <span class="n">gen_list_keys_for_tests</span><span class="p">()</span>

    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="n">new_rand_val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">pipe_elem</span> <span class="ow">in</span> <span class="n">pipe_list</span>
    <span class="p">)</span>

    <span class="n">action_over_list_f</span><span class="p">(</span><span class="n">pipe_list</span><span class="p">,</span> <span class="n">args</span><span class="p">[</span><span class="s1">&#39;chains&#39;</span><span class="p">][</span><span class="s1">&#39;pipe&#39;</span><span class="p">])</span>

    <span class="k">assert</span> <span class="nb">any</span><span class="p">(</span>
        <span class="n">rand_key</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span>
        <span class="n">new_rand_val</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">pipe_elem</span> <span class="ow">in</span> <span class="n">pipe_list</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">test_replacement_f_list</span><span class="p">():</span>

    <span class="n">pipe_list</span><span class="p">,</span> <span class="n">rand_id</span><span class="p">,</span> <span class="n">rand_key</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">new_rand_val</span> <span class="o">=</span> <span class="n">gen_list_keys_for_tests</span><span class="p">()</span>

    <span class="n">mod_conf</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;chains&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;pipe&#39;</span><span class="p">:</span> <span class="n">pipe_list</span><span class="p">}}</span>

    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="n">new_rand_val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">pipe_elem</span> <span class="ow">in</span> <span class="n">mod_conf</span><span class="p">[</span><span class="s1">&#39;chains&#39;</span><span class="p">][</span><span class="s1">&#39;pipe&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">replacement_f</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">mod_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">any</span><span class="p">(</span>
        <span class="n">rand_key</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span>
        <span class="n">new_rand_val</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">pipe_elem</span> <span class="ow">in</span> <span class="n">mod_conf</span><span class="p">[</span><span class="s1">&#39;chains&#39;</span><span class="p">][</span><span class="s1">&#39;pipe&#39;</span><span class="p">]</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">test_replacement_f_val</span><span class="p">():</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;key3&#39;</span><span class="p">:</span> <span class="s1">&#39;newvalue&#39;</span><span class="p">}</span>
    <span class="n">mod_conf</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;key1&#39;</span><span class="p">:</span> <span class="s1">&#39;val1&#39;</span><span class="p">,</span> <span class="s1">&#39;key2&#39;</span><span class="p">:</span> <span class="s1">&#39;val2&#39;</span><span class="p">,</span> <span class="s1">&#39;key3&#39;</span><span class="p">:</span> <span class="s1">&#39;val3&#39;</span><span class="p">}</span>
    <span class="n">replacement_f</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">mod_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="n">arg_k</span> <span class="ow">in</span> <span class="n">mod_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">arg_v</span> <span class="ow">in</span> <span class="n">mod_conf</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">arg_k</span><span class="p">,</span> <span class="n">arg_v</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">test_replacement_f_dict</span><span class="p">():</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;1_key_3&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;2_key_2&#39;</span><span class="p">:</span> <span class="s1">&#39;newvalue&#39;</span><span class="p">}}</span>
    <span class="n">mod_conf</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;1_key_3&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;2_key_2&#39;</span><span class="p">:</span> <span class="s1">&#39;oldvalue&#39;</span><span class="p">},</span> <span class="s1">&#39;0_key_&#39;</span><span class="p">:</span> <span class="s1">&#39;0_val&#39;</span><span class="p">}</span>
    <span class="n">replacement_f</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">mod_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">mod_conf</span><span class="p">[</span><span class="s1">&#39;1_key_3&#39;</span><span class="p">][</span><span class="s1">&#39;2_key_2&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;newvalue&#39;</span>


<span class="n">test_action_over_list_f</span><span class="p">()</span>
<span class="n">test_replacement_f_list</span><span class="p">()</span>
<span class="n">test_replacement_f_val</span><span class="p">()</span>
<span class="n">test_replacement_f_dict</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="updates_faq_config_file" class="doc_header"><code>updates_faq_config_file</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L66" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>updates_faq_config_file</code>(<strong><code>configs_path</code></strong>, <strong>**<code>args</code></strong>)</p>
</blockquote>
<p>Updates deepplavov json config file</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#test updates_faq_config_file</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>


<span class="k">def</span> <span class="nf">gen_list_keys_for_tests</span><span class="p">():</span>

    <span class="n">str_n</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span><span class="si">:</span><span class="s1">1</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="n">gen_dict_list</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">),</span>
        <span class="s1">&#39;key1&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;v1&#39;</span><span class="p">),</span>
        <span class="s1">&#39;key2&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;v2&#39;</span><span class="p">),</span>
        <span class="s1">&#39;key3&#39;</span><span class="p">:</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;v3&#39;</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">pipe_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">gen_dict_list</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))]</span>

    <span class="n">rand_id</span> <span class="o">=</span> <span class="n">pipe_list</span><span class="p">[</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipe_list</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)][</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
    <span class="n">rand_key</span> <span class="o">=</span>  <span class="sa">f</span><span class="s1">&#39;key</span><span class="si">{</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span> 

    <span class="n">new_rand_val</span> <span class="o">=</span> <span class="n">str_n</span><span class="p">(</span><span class="s1">&#39;new&#39;</span><span class="p">)</span>
    <span class="n">pipe_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pipe&#39;</span><span class="p">:</span> <span class="p">[{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">rand_id</span><span class="p">},</span> <span class="p">{</span><span class="n">rand_key</span><span class="p">:</span> <span class="n">new_rand_val</span><span class="p">}]}</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;chainer&#39;</span><span class="p">:</span> <span class="n">pipe_dict</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">pipe_list</span><span class="p">,</span> <span class="n">rand_id</span><span class="p">,</span> <span class="n">rand_key</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">new_rand_val</span>


<span class="k">def</span> <span class="nf">test_updates_faq_config_file_update_string</span><span class="p">():</span>

    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">tmp_config_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;tmp_file.json&#39;</span><span class="p">)</span>

        <span class="n">copyfile</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">faq</span><span class="o">.</span><span class="n">tfidf_logreg_en_faq</span><span class="p">,</span> <span class="n">tmp_config_file</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">tmp_config_file</span><span class="p">)</span>

        <span class="n">updates_faq_config_file</span><span class="p">(</span>
            <span class="n">configs_path</span><span class="o">=</span><span class="n">tmp_config_file</span><span class="p">,</span>
            <span class="n">dataset_reader</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="s1">&#39;fictional_csv_file.csv&#39;</span><span class="p">}</span>
        <span class="p">)</span>

        <span class="n">config_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">tmp_config_file</span><span class="p">))</span>
        <span class="k">assert</span> <span class="s1">&#39;data_path&#39;</span> <span class="ow">in</span> <span class="n">config_json</span><span class="p">[</span><span class="s1">&#39;dataset_reader&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">test_updates_faq_config_file_update_list</span><span class="p">():</span>

    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">tmp_config_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;tmp_file.json&#39;</span><span class="p">)</span>

        <span class="n">pipe_list</span><span class="p">,</span> <span class="n">rand_id</span><span class="p">,</span> <span class="n">rand_key</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">new_rand_val</span> <span class="o">=</span> <span class="n">gen_list_keys_for_tests</span><span class="p">(</span>
        <span class="p">)</span>
        <span class="n">mod_conf</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;chainer&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;pipe&#39;</span><span class="p">:</span> <span class="n">pipe_list</span>
            <span class="p">},</span>
            <span class="s1">&#39;dataset_reader&#39;</span><span class="p">:</span> <span class="s1">&#39;dataset_reader_dictionary&#39;</span>
        <span class="p">}</span>

        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">mod_conf</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="n">tmp_config_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">))</span>

        <span class="k">assert</span> <span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">tmp_config_file</span><span class="p">)</span>

        <span class="n">updates_faq_config_file</span><span class="p">(</span><span class="n">configs_path</span><span class="o">=</span><span class="n">tmp_config_file</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span><span class="p">)</span>

        <span class="n">config_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">tmp_config_file</span><span class="p">))</span>
   
        <span class="k">assert</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">rand_key</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">new_rand_val</span> <span class="ow">in</span> <span class="n">pipe_elem</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">pipe_elem</span> <span class="ow">in</span> <span class="n">config_json</span><span class="p">[</span><span class="s1">&#39;chainer&#39;</span><span class="p">][</span><span class="s1">&#39;pipe&#39;</span><span class="p">]</span>
        <span class="p">)</span>


<span class="n">test_updates_faq_config_file_update_string</span><span class="p">()</span>
<span class="n">test_updates_faq_config_file_update_list</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="select_faq_responses" class="doc_header"><code>select_faq_responses</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L83" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>select_faq_responses</code>(<strong><code>faq_model</code></strong>, <strong><code>question</code></strong>)</p>
</blockquote>
<p>Calls Deeppavlov FAQ model</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#test faq responses</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>


<span class="k">def</span> <span class="nf">gen_mock_csv_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">):</span>

    <span class="n">temp_faq_csv</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;tmp_faq.csv&#39;</span><span class="p">)</span>

    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">faqs</span><span class="p">)</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">temp_faq_csv</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">temp_faq_csv</span>


<span class="k">def</span> <span class="nf">gen_mock_vocab_answers</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocabs</span><span class="p">):</span>

    <span class="n">temp_dict_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_vocab_answers.dict&#39;</span><span class="p">)</span>
    <span class="n">vocabs_text</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">t</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vocabs</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">vocabs</span><span class="p">[</span><span class="s1">&#39;freq&#39;</span><span class="p">])</span>
    <span class="p">)</span>

    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">temp_dict_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">vocabs_text</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">temp_dict_file</span>


<span class="k">def</span> <span class="nf">gen_faq_config</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">faq_file</span><span class="p">):</span>

    <span class="n">temp_configs_faq</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_config_faq.json&#39;</span><span class="p">)</span>
    <span class="n">copyfile</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">faq</span><span class="o">.</span><span class="n">tfidf_logreg_en_faq</span><span class="p">,</span> <span class="n">temp_configs_faq</span><span class="p">)</span>

    <span class="n">changes_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;save_path&#39;</span><span class="p">:</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="s1">&#39;load_path&#39;</span><span class="p">:</span> <span class="n">vocab_file</span><span class="p">}</span>
    <span class="n">id_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="s1">&#39;answers_vocab&#39;</span><span class="p">}</span>

    <span class="n">updates_faq_config_file</span><span class="p">(</span>
        <span class="n">configs_path</span><span class="o">=</span><span class="n">temp_configs_faq</span><span class="p">,</span>
        <span class="n">chainer</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;pipe&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">id_dict</span><span class="p">,</span> <span class="n">changes_dict</span><span class="p">]},</span>
        <span class="n">dataset_reader</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">faq_file</span><span class="p">}</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">temp_configs_faq</span>


<span class="k">def</span> <span class="nf">test_faq_response_with_minimum_faqs_in_dataframe_fail_case</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">faqs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;Question&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Is Covid erradicated?&#39;</span><span class="p">],</span>
            <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Definitely not!&#39;</span><span class="p">]</span>
        <span class="p">}</span>

        <span class="n">vocabs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;This is a vocab example&#39;</span><span class="p">],</span> <span class="s1">&#39;freq&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]}</span>

        <span class="n">faq_file</span> <span class="o">=</span> <span class="n">gen_mock_csv_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">)</span>
        <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">gen_mock_vocab_answers</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocabs</span><span class="p">)</span>

        <span class="n">configs_file</span> <span class="o">=</span> <span class="n">gen_faq_config</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">faq_file</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">select_faq_responses</span><span class="p">(</span>
                <span class="n">question</span><span class="o">=</span><span class="s1">&#39;Is Enrique the prettiest person in town?&#39;</span><span class="p">,</span>
                <span class="n">faq_model</span><span class="o">=</span><span class="n">train_model</span><span class="p">(</span><span class="n">configs_file</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">assert</span> <span class="kc">False</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">assert</span> <span class="kc">True</span>


<span class="k">def</span> <span class="nf">test_faq_response_with_minimum_faqs_in_dataframe_success_case</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">faqs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;Question&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Is Covid erradicated?&#39;</span><span class="p">,</span> <span class="s1">&#39;Who is the current POTUS?&#39;</span><span class="p">],</span>
            <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Definitely not!&#39;</span><span class="p">,</span> <span class="s1">&#39;Donald Trump&#39;</span><span class="p">]</span>
        <span class="p">}</span>

        <span class="n">vocabs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;This is a vocab example&#39;</span><span class="p">],</span> <span class="s1">&#39;freq&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]}</span>

        <span class="n">faq_file</span> <span class="o">=</span> <span class="n">gen_mock_csv_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">)</span>
        <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">gen_mock_vocab_answers</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocabs</span><span class="p">)</span>

        <span class="n">configs_file</span> <span class="o">=</span> <span class="n">gen_faq_config</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">faq_file</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">select_faq_responses</span><span class="p">(</span>
            <span class="n">question</span><span class="o">=</span><span class="s1">&#39;Is Enrique the prettiest person in town?&#39;</span><span class="p">,</span>
            <span class="n">faq_model</span><span class="o">=</span><span class="n">train_model</span><span class="p">(</span><span class="n">configs_file</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;Donald Trump&#39;</span><span class="p">]</span>

        
        
<span class="k">def</span> <span class="nf">test_faq_response_with_minimum_answers_vocab_success_case</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">faqs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;Question&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Is Covid erradicated?&#39;</span><span class="p">,</span> <span class="s1">&#39;Who is the current POTUS?&#39;</span><span class="p">],</span>
            <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Definitely not!&#39;</span><span class="p">,</span> <span class="s1">&#39;Donald Trump&#39;</span><span class="p">]</span>
        <span class="p">}</span>

        <span class="n">vocabs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;freq&#39;</span><span class="p">:</span> <span class="p">[]}</span>

        <span class="n">faq_file</span> <span class="o">=</span> <span class="n">gen_mock_csv_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">)</span>
        <span class="n">vocab_file</span> <span class="o">=</span> <span class="n">gen_mock_vocab_answers</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocabs</span><span class="p">)</span>

        <span class="n">configs_file</span> <span class="o">=</span> <span class="n">gen_faq_config</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">,</span> <span class="n">faq_file</span><span class="p">)</span>

        <span class="n">select_faq_responses</span><span class="p">(</span>
            <span class="n">question</span><span class="o">=</span><span class="s1">&#39;Is Enrique the prettiest person in town?&#39;</span><span class="p">,</span>
            <span class="n">faq_model</span><span class="o">=</span><span class="n">train_model</span><span class="p">(</span><span class="n">configs_file</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;Donald Trump&#39;</span><span class="p">]</span>

<span class="n">test_faq_response_with_minimum_faqs_in_dataframe_fail_case</span><span class="p">()</span>
<span class="n">test_faq_response_with_minimum_faqs_in_dataframe_success_case</span><span class="p">()</span>
<span class="n">test_faq_response_with_minimum_answers_vocab_success_case</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>04:59:57 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
04:59:58 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /faq/mipt/en_mipt_faq_v4.tar.gz.md5 HTTP/1.1&#34; 200 189
04:59:58 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
04:59:58 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /faq/mipt/en_mipt_faq_v4.tar.gz HTTP/1.1&#34; 200 12276
2020-06-17 16:59:58.508 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz
04:59:58 INFO:Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz
100%|| 12.3k/12.3k [00:00&lt;00:00, 7.35MB/s]
2020-06-17 16:59:58.537 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 242: Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt
04:59:58 INFO:Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt
[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...
[nltk_data]   Unzipping corpora/stopwords.zip.
[nltk_data] Downloading package perluniprops to
[nltk_data]     /home/jovyan/nltk_data...
[nltk_data]   Unzipping misc/perluniprops.zip.
[nltk_data] Downloading package nonbreaking_prefixes to
[nltk_data]     /home/jovyan/nltk_data...
[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.
2020-06-17 17:00:03.374 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:03 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:03.376 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:00:03 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:00:03.377 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:03 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:03.403 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:00:03 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:00:03.417 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:03 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:03.420 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /tmp/tmpyikdqnxw/temp_vocab_answers.dict]
05:00:03 INFO:[loading vocabulary from /tmp/tmpyikdqnxw/temp_vocab_answers.dict]
2020-06-17 17:00:03.422 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /tmp/tmpyikdqnxw/temp_vocab_answers.dict]
05:00:03 INFO:[saving vocabulary to /tmp/tmpyikdqnxw/temp_vocab_answers.dict]
2020-06-17 17:00:03.424 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:03 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:03.426 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:00:03 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:00:03.427 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:03 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:03.433 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:00:03 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
05:00:03 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:00:03 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /faq/mipt/en_mipt_faq_v4.tar.gz.md5 HTTP/1.1&#34; 200 189
05:00:03 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:00:04 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /faq/mipt/en_mipt_faq_v4.tar.gz HTTP/1.1&#34; 200 12276
2020-06-17 17:00:04.247 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz
05:00:04 INFO:Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz
100%|| 12.3k/12.3k [00:00&lt;00:00, 22.0MB/s]
2020-06-17 17:00:04.252 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 242: Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt
05:00:04 INFO:Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt
2020-06-17 17:00:04.931 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:04 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:04.932 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:00:04 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:00:04.933 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:04 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:04.940 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:00:04 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:00:04.943 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:04 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:04.945 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
05:00:04 INFO:[loading vocabulary from /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
2020-06-17 17:00:04.947 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
05:00:04 INFO:[saving vocabulary to /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
2020-06-17 17:00:04.948 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:04 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:04.950 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:00:04 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:00:04.951 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:04 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:04.956 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:00:04 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:00:05.8 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:05 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:05.744 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:05 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:05.746 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:00:05 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:00:05.746 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:05 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:05.748 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
05:00:05 INFO:[loading vocabulary from /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
2020-06-17 17:00:05.750 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:05 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:05.752 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:00:05 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:00:05.753 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:05 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:06.454 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:06 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:06.455 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:00:06 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:00:06.456 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:06 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:06.457 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
05:00:06 INFO:[loading vocabulary from /tmp/tmpkqf05ygl/temp_vocab_answers.dict]
2020-06-17 17:00:06.459 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:06 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:06.460 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:00:06 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:00:06.461 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:06 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:06 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:00:06 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /faq/mipt/en_mipt_faq_v4.tar.gz.md5 HTTP/1.1&#34; 200 189
05:00:06 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:00:07 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /faq/mipt/en_mipt_faq_v4.tar.gz HTTP/1.1&#34; 200 12276
2020-06-17 17:00:07.292 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz
05:00:07 INFO:Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz
100%|| 12.3k/12.3k [00:00&lt;00:00, 6.84MB/s]
2020-06-17 17:00:07.311 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 242: Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt
05:00:07 INFO:Extracting /home/jovyan/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /home/jovyan/.deeppavlov/models/faq/mipt
2020-06-17 17:00:08.79 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:08 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:08.80 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:00:08 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:00:08.81 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:08 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:08.88 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:00:08 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:00:08.90 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:08 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:08.92 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /tmp/tmpdyb41g49/temp_vocab_answers.dict]
05:00:08 INFO:[loading vocabulary from /tmp/tmpdyb41g49/temp_vocab_answers.dict]
2020-06-17 17:00:08.94 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /tmp/tmpdyb41g49/temp_vocab_answers.dict]
05:00:08 INFO:[saving vocabulary to /tmp/tmpdyb41g49/temp_vocab_answers.dict]
2020-06-17 17:00:08.96 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:08 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:08.97 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:00:08 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:00:08.98 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:08 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:08.104 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:00:08 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:00:08.106 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:08 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:08.795 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:08 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:08.796 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:00:08 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:00:08.797 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:08 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:08.799 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /tmp/tmpdyb41g49/temp_vocab_answers.dict]
05:00:08 INFO:[loading vocabulary from /tmp/tmpdyb41g49/temp_vocab_answers.dict]
2020-06-17 17:00:08.800 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:08 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:08.801 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:00:08 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:00:08.802 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:08 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:09.534 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:00:09 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:00:09.535 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:00:09 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:00:09.536 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:09 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:00:09.538 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /tmp/tmpdyb41g49/temp_vocab_answers.dict]
05:00:09 INFO:[loading vocabulary from /tmp/tmpdyb41g49/temp_vocab_answers.dict]
2020-06-17 17:00:09.540 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:00:09 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:00:09.541 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:00:09 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:00:09.542 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:00:09 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="select_squad_responses" class="doc_header"><code>select_squad_responses</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L89" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>select_squad_responses</code>(<strong><code>contexts</code></strong>, <strong><code>squad_model</code></strong>, <strong><code>question</code></strong>, <strong><code>best_results</code></strong>=<em><code>1</code></em>)</p>
</blockquote>
<p>Calls Deeppavlov BERT and RNET Context Question Answering</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#test select_squad_responses</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>

<span class="n">empty</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="n">spacex</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;SpaceX&#39;</span><span class="p">],</span>
    <span class="s1">&#39;context&#39;</span><span class="p">:</span>
        <span class="p">[</span>
            <span class="sd">&#39;&#39;&#39;Space Exploration Technologies Corp., trading as SpaceX, is an American aerospace manufacturer and space transportation</span>
<span class="sd">services company headquartered in Hawthorne, California. It was founded in 2002 by Elon Musk with the goal of reducing space </span>
<span class="sd">transportation costs to enable the colonization of Mars. SpaceX has developed several launch vehicles, the Starlink satellite</span>
<span class="sd">constellation, and the Dragon spacecraft. It is widely considered among the most successful private spaceflight companies.&#39;&#39;&#39;</span>
        <span class="p">]</span>
<span class="p">}</span>

<span class="n">intekglobal</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Intekglobal&#39;</span><span class="p">,</span> <span class="s1">&#39;InG&#39;</span><span class="p">],</span>
    <span class="s1">&#39;context&#39;</span><span class="p">:</span>
        <span class="p">[</span>
            <span class="s1">&#39;Intekglobal has its headquarters located in TJ&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Intekglobal is in the north of mexico&#39;</span>
        <span class="p">]</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">assert_squad_model</span><span class="p">(</span>
    <span class="n">contexts</span><span class="p">,</span> <span class="n">squad_model</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="n">expected_responses</span><span class="p">,</span> <span class="o">**</span><span class="n">args</span>
<span class="p">):</span>
    <span class="n">responses</span><span class="p">,</span> <span class="n">top_responses</span> <span class="o">=</span> <span class="n">select_squad_responses</span><span class="p">(</span>
        <span class="n">contexts</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">contexts</span><span class="p">),</span>
        <span class="n">squad_model</span><span class="o">=</span><span class="n">squad_model</span><span class="p">,</span>
        <span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span>
        <span class="o">**</span><span class="n">args</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="n">top_responses</span> <span class="o">==</span> <span class="n">expected_responses</span>


<span class="k">def</span> <span class="nf">test_squad_bert</span><span class="p">():</span>

    <span class="n">bert</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">squad</span><span class="o">.</span><span class="n">squad_bert</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">assert_squad_model</span><span class="p">(</span>
        <span class="n">empty</span><span class="p">,</span>
        <span class="n">bert</span><span class="p">,</span>
        <span class="s1">&#39;Is an empty response expected?&#39;</span><span class="p">,</span>
        <span class="n">expected_responses</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">best_results</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">)</span>

    <span class="n">assert_squad_model</span><span class="p">(</span>
        <span class="n">spacex</span><span class="p">,</span> <span class="n">bert</span><span class="p">,</span> <span class="s1">&#39;Who founded SpaceX?&#39;</span><span class="p">,</span> <span class="n">expected_responses</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Elon Musk&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">assert_squad_model</span><span class="p">(</span>
        <span class="n">intekglobal</span><span class="p">,</span>
        <span class="n">bert</span><span class="p">,</span>
        <span class="s1">&#39;Where is Intekglobal located?&#39;</span><span class="p">,</span>
        <span class="n">expected_responses</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;north of mexico&#39;</span><span class="p">,</span><span class="s1">&#39;TJ&#39;</span><span class="p">],</span>
        <span class="n">best_results</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">test_squad_rnet</span><span class="p">():</span>

    <span class="n">bert</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">squad</span><span class="o">.</span><span class="n">squad</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">assert_squad_model</span><span class="p">(</span>
        <span class="n">empty</span><span class="p">,</span>
        <span class="n">bert</span><span class="p">,</span>
        <span class="s1">&#39;Is an empty response expected?&#39;</span><span class="p">,</span>
        <span class="n">expected_responses</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">best_results</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span>

    <span class="n">assert_squad_model</span><span class="p">(</span>
        <span class="n">spacex</span><span class="p">,</span> <span class="n">bert</span><span class="p">,</span> <span class="s1">&#39;Who founded SpaceX?&#39;</span><span class="p">,</span> <span class="n">expected_responses</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Elon Musk&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">assert_squad_model</span><span class="p">(</span>
        <span class="n">intekglobal</span><span class="p">,</span>
        <span class="n">bert</span><span class="p">,</span>
        <span class="s1">&#39;Where is Intekglobal located?&#39;</span><span class="p">,</span>
        <span class="n">expected_responses</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;north of mexico&#39;</span><span class="p">,</span><span class="s1">&#39;TJ&#39;</span><span class="p">],</span>
        <span class="n">best_results</span><span class="o">=</span><span class="mi">2</span>
    <span class="p">)</span>

<span class="n">test_squad_bert</span><span class="p">()</span>
<span class="n">test_squad_rnet</span><span class="p">()</span>
<span class="k">del</span> <span class="n">spacex</span><span class="p">,</span> <span class="n">empty</span><span class="p">,</span> <span class="n">intekglobal</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>05:00:09 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:00:10 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /deeppavlov_data/squad_bert.tar.gz.md5 HTTP/1.1&#34; 200 184
05:00:10 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:00:10 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /deeppavlov_data/squad_bert.tar.gz HTTP/1.1&#34; 200 402313916
2020-06-17 17:00:10.554 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz to /home/jovyan/.deeppavlov/squad_bert.tar.gz
05:00:10 INFO:Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_bert.tar.gz to /home/jovyan/.deeppavlov/squad_bert.tar.gz
100%|| 402M/402M [03:53&lt;00:00, 1.72MB/s] 
2020-06-17 17:04:04.383 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 242: Extracting /home/jovyan/.deeppavlov/squad_bert.tar.gz archive into /home/jovyan/.deeppavlov/models
05:04:04 INFO:Extracting /home/jovyan/.deeppavlov/squad_bert.tar.gz archive into /home/jovyan/.deeppavlov/models
05:04:08 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:04:08 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /deeppavlov_data/bert/cased_L-12_H-768_A-12.zip.md5 HTTP/1.1&#34; 200 386
05:04:08 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:04:08 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /deeppavlov_data/bert/cased_L-12_H-768_A-12.zip HTTP/1.1&#34; 200 404261442
2020-06-17 17:04:08.898 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip to /home/jovyan/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip
05:04:08 INFO:Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip to /home/jovyan/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip
100%|| 404M/404M [04:30&lt;00:00, 1.49MB/s] 
2020-06-17 17:08:39.483 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 242: Extracting /home/jovyan/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip archive into /home/jovyan/.deeppavlov/downloads/bert_models
05:08:39 INFO:Extracting /home/jovyan/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip archive into /home/jovyan/.deeppavlov/downloads/bert_models
05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:81: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:178: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

05:08:45 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.

05:08:45 WARNING:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

05:08:46 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
05:08:46 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
05:08:46 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
05:08:46 WARNING:From /opt/conda/lib/python3.7/site-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.

05:08:48 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:154: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.

05:08:48 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:166: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

05:08:48 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.

05:08:48 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

05:08:48 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

05:08:57 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:89: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

05:09:05 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/bert/bert_squad.py:94: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2020-06-17 17:09:05.604 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:09:05 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:09:05 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

05:09:05 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model
05:09:07 DEBUG:Responses: []
05:09:07 DEBUG:Top Responses: []
05:09:09 DEBUG:Responses: [list([[&#39;Elon Musk&#39;], [203], [50257280.0]])]
05:09:09 DEBUG:Top Responses: [&#39;Elon Musk&#39;]
05:09:10 DEBUG:Responses: [list([[&#39;TJ&#39;], [44], [6978.86279296875]])
 list([[&#39;north of mexico&#39;], [22], [81567.328125]])]
05:09:10 DEBUG:Top Responses: [&#39;north of mexico&#39;, &#39;TJ&#39;]
05:09:10 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:09:10 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /embeddings/wiki-news-300d-1M-char.vec.md5 HTTP/1.1&#34; 200 61
05:09:10 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:09:11 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /embeddings/wiki-news-300d-1M-char.vec HTTP/1.1&#34; 200 7733456
2020-06-17 17:09:11.375 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec to /home/jovyan/.deeppavlov/downloads/embeddings/wiki-news-300d-1M-char.vec
05:09:11 INFO:Downloading from http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M-char.vec to /home/jovyan/.deeppavlov/downloads/embeddings/wiki-news-300d-1M-char.vec
100%|| 7.73M/7.73M [00:05&lt;00:00, 1.46MB/s]
05:09:16 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:09:17 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz.md5 HTTP/1.1&#34; 200 389
05:09:17 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:09:17 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz HTTP/1.1&#34; 200 222203159
2020-06-17 17:09:17.491 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz to /home/jovyan/.deeppavlov/squad_model_1.4_cpu_compatible.tar.gz
05:09:17 INFO:Downloading from http://files.deeppavlov.ai/deeppavlov_data/squad_model_1.4_cpu_compatible.tar.gz to /home/jovyan/.deeppavlov/squad_model_1.4_cpu_compatible.tar.gz
100%|| 222M/222M [03:14&lt;00:00, 1.14MB/s] 
2020-06-17 17:12:31.647 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 242: Extracting /home/jovyan/.deeppavlov/squad_model_1.4_cpu_compatible.tar.gz archive into /home/jovyan/.deeppavlov/models
05:12:31 INFO:Extracting /home/jovyan/.deeppavlov/squad_model_1.4_cpu_compatible.tar.gz archive into /home/jovyan/.deeppavlov/models
05:12:35 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:12:36 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /embeddings/wiki-news-300d-1M.vec.md5 HTTP/1.1&#34; 200 56
05:12:36 DEBUG:Starting new HTTP connection (1): files.deeppavlov.ai:80
05:12:36 DEBUG:http://files.deeppavlov.ai:80 &#34;GET /embeddings/wiki-news-300d-1M.vec HTTP/1.1&#34; 200 2260102345
2020-06-17 17:12:36.610 INFO in &#39;deeppavlov.core.data.utils&#39;[&#39;utils&#39;] at line 80: Downloading from http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec to /home/jovyan/.deeppavlov/downloads/embeddings/wiki-news-300d-1M.vec
05:12:36 INFO:Downloading from http://files.deeppavlov.ai/embeddings/wiki-news-300d-1M.vec to /home/jovyan/.deeppavlov/downloads/embeddings/wiki-news-300d-1M.vec
100%|| 2.26G/2.26G [12:59&lt;00:00, 2.90MB/s] 
2020-06-17 17:25:35.756 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
05:25:35 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
2020-06-17 17:25:40.892 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
05:25:40 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
2020-06-17 17:25:43.157 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:25:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:122: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/layers/tf_layers.py:591: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/layers/tf_layers.py:596: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:133: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:139: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py:155: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/core/layers/tf_layers.py:808: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.
Instructions for updating:
seq_dim is deprecated, use seq_axis instead
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.
Instructions for updating:
batch_dim is deprecated, use batch_axis instead
2020-06-17 17:25:43.276 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:25:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:25:43.385 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:25:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:25:43.461 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:25:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:25:43 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/squad/utils.py:101: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

05:25:45 WARNING:From /opt/conda/lib/python3.7/site-packages/deeppavlov/models/squad/utils.py:139: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.

05:25:51 WARNING:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/clip_ops.py:172: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-06-17 17:25:54.530 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:25:54 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:25:54 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model
05:25:56 DEBUG:Responses: []
05:25:56 DEBUG:Top Responses: []
05:25:58 DEBUG:Responses: [list([[&#39;Elon Musk&#39;], [203], [36056324.0]])]
05:25:58 DEBUG:Top Responses: [&#39;Elon Musk&#39;]
05:25:58 DEBUG:Responses: [list([[&#39;TJ&#39;], [44], [564.4996948242188]])
 list([[&#39;north of mexico&#39;], [22], [138151.90625]])]
05:25:58 DEBUG:Top Responses: [&#39;north of mexico&#39;, &#39;TJ&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_qa_models" class="doc_header"><code>load_qa_models</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L108" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_qa_models</code>(<strong><code>config_rnet</code></strong>=<em><code>PosixPath('/opt/conda/lib/python3.7/site-packages/deeppavlov/configs/squad/squad.json')</code></em>, <strong><code>config_bert</code></strong>=<em><code>PosixPath('/opt/conda/lib/python3.7/site-packages/deeppavlov/configs/squad/squad_bert.json')</code></em>, <strong><code>config_tfidf</code></strong>=<em><code>PosixPath('/opt/conda/lib/python3.7/site-packages/deeppavlov/configs/faq/tfidf_logreg_en_faq.json')</code></em>, <strong><code>download</code></strong>=<em><code>True</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="format_responses" class="doc_header"><code>format_responses</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L127" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>format_responses</code>(<strong><code>question</code></strong>, <strong><code>responses</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_responses" class="doc_header"><code>get_responses</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L134" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_responses</code>(<strong><code>contexts</code></strong>, <strong><code>question</code></strong>, <strong><code>qa_models</code></strong>, <strong><code>nb_squad_results</code></strong>=<em><code>1</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test get_responses</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>

<span class="n">intekglobal_context</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Intekglobal&#39;</span><span class="p">,</span> <span class="s1">&#39;InG&#39;</span><span class="p">],</span>
    <span class="s1">&#39;context&#39;</span><span class="p">:</span>
        <span class="p">[</span>
            <span class="s1">&#39;Intekglobal has its headquarters located in TJ&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Intekglobal is in the north of mexico&#39;</span>
        <span class="p">]</span>
<span class="p">}</span>

<span class="n">intekglobal_faqs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Question&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Is Intekglobal an IT company?&#39;</span><span class="p">,</span> <span class="s1">&#39;Where can I apply?&#39;</span><span class="p">],</span>
    <span class="s1">&#39;Answer&#39;</span><span class="p">:</span>
        <span class="p">[</span><span class="s1">&#39;Yes it is!&#39;</span><span class="p">,</span> <span class="s1">&#39;Please refer the our website for further information&#39;</span><span class="p">]</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">):</span>

    <span class="n">faq_files</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_faq.csv&#39;</span><span class="p">),</span>
        <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_config_faq.json&#39;</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">faqs</span><span class="p">)</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">faq_files</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">copyfile</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">faq</span><span class="o">.</span><span class="n">tfidf_logreg_en_faq</span><span class="p">,</span> <span class="n">faq_files</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">])</span>

    <span class="n">updates_faq_config_file</span><span class="p">(</span>
        <span class="n">configs_path</span><span class="o">=</span><span class="n">faq_files</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">],</span>
        <span class="n">dataset_reader</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">faq_files</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]}</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">faq_files</span>


<span class="k">def</span> <span class="nf">test_get_intekglobal_responses</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">faq_files</span> <span class="o">=</span> <span class="n">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">intekglobal_faqs</span><span class="p">)</span>
        <span class="n">qa_models</span> <span class="o">=</span> <span class="n">load_qa_models</span><span class="p">(</span>
            <span class="n">config_tfidf</span><span class="o">=</span><span class="n">faq_files</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">],</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">responses</span><span class="p">,</span> <span class="n">format_responses</span> <span class="o">=</span> <span class="n">get_responses</span><span class="p">(</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">intekglobal_context</span><span class="p">),</span>
            <span class="s1">&#39;Where is Intekglobal?&#39;</span><span class="p">,</span>
            <span class="n">qa_models</span><span class="p">,</span>
            <span class="n">nb_squad_results</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">format_responses</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">response</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;north of mexico&#39;</span><span class="p">,</span> <span class="s1">&#39;TJ&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes it is!&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">responses</span>
        <span class="p">)</span>
        <span class="c1">#assert &#39;&#39;&#39; Where is Intekglobal?:</span>

<span class="c1">#0: north of mexico</span>
<span class="c1">#1: Yes it is!</span>
<span class="c1">#2: TJ</span>
<span class="c1">#        &#39;&#39;&#39;.strip() == format_responses.strip()</span>


<span class="k">def</span> <span class="nf">test_get_responses_with_empty_context</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>
        <span class="n">min_faqs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Question&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Minimum number of questions?&#39;</span><span class="p">,</span><span class="s1">&#39;This is the other question?&#39;</span><span class="p">],</span> <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Two&#39;</span><span class="p">,</span><span class="s1">&#39;yes&#39;</span><span class="p">]}</span>
        <span class="n">faq_files</span> <span class="o">=</span> <span class="n">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">min_faqs</span><span class="p">)</span>

        <span class="n">qa_models</span> <span class="o">=</span> <span class="n">load_qa_models</span><span class="p">(</span>
            <span class="n">config_tfidf</span><span class="o">=</span><span class="n">faq_files</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">],</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">empty_context</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="p">[]}</span>

        <span class="n">responses</span><span class="p">,</span> <span class="n">format_responses</span> <span class="o">=</span> <span class="n">get_responses</span><span class="p">(</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">empty_context</span><span class="p">),</span>
            <span class="s1">&#39;What is the minimun number of FAQ questions&#39;</span><span class="p">,</span>
            <span class="n">qa_models</span><span class="p">,</span>
            <span class="n">nb_squad_results</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">format_responses</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">responses</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;Two&#39;</span><span class="p">]</span>


<span class="n">test_get_intekglobal_responses</span><span class="p">()</span>
<span class="n">test_get_responses_with_empty_context</span><span class="p">()</span>

<span class="k">del</span> <span class="n">intekglobal_context</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2020-06-17 17:26:04.981 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
05:26:04 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
2020-06-17 17:26:10.878 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
05:26:10 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
2020-06-17 17:26:11.681 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:26:11 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:26:11.782 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:26:11 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:26:11.885 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:26:11 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:26:11.960 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:26:11 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:26:22.999 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:26:22 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:26:23 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model
2020-06-17 17:27:10.704 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:27:10 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:27:15 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model
2020-06-17 17:28:11.627 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:28:11 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:28:11.841 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:28:11 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:28:11.866 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:28:11 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:28:13.260 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:28:13 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:28:13.512 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:28:13 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:28:13.534 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:28:13 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:28:13.855 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:28:13 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:28:13.863 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:28:13 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:28:13.869 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:28:13 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:28:13.873 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:28:13 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:28:14.387 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:28:14 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:28:14.858 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:28:14 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:28:19.255 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:28:19 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:28:19.256 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:28:19 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:28:19.257 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:28:19.259 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:28:19 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:28:19.261 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:28:19 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:28:19.262 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:28:19 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:28:19.263 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:28:19.919 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:28:19 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:28:19.920 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:28:19 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:28:19.921 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:28:19.924 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:28:19 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:28:19.925 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:28:19 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:28:19.927 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:28:19 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:28:19.928 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:28:19 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:28:29 DEBUG:Responses: [list([[&#39;TJ&#39;], [44], [120.95974731445312]])
 list([[&#39;north of mexico&#39;], [22], [174602.40625]])]
05:28:29 DEBUG:Top Responses: [&#39;north of mexico&#39;, &#39;TJ&#39;]
05:28:31 DEBUG:Responses: [list([[&#39;TJ&#39;], [44], [22507.34375]])
 list([[&#39;north of mexico&#39;], [22], [269778.3125]])]
05:28:31 DEBUG:Top Responses: [&#39;north of mexico&#39;, &#39;TJ&#39;]
05:28:32 DEBUG:[&#39;north of mexico&#39;, &#39;TJ&#39;, &#39;north of mexico&#39;, &#39;TJ&#39;, &#39;Yes it is!&#39;]
05:28:32 DEBUG:Where is Intekglobal?:

0: TJ
1: north of mexico
2: Yes it is!

2020-06-17 17:28:33.370 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
05:28:33 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
2020-06-17 17:28:41.755 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
05:28:41 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
2020-06-17 17:28:43.403 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:28:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:28:43.535 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:28:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:28:43.635 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:28:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:28:43.707 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:28:43 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:28:55.787 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:28:55 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:28:55 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model
2020-06-17 17:29:11.532 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:29:11 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:29:11 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model
2020-06-17 17:29:21.568 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:29:21 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:29:21.570 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:29:21 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:29:21.571 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:29:21 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:29:21.579 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:29:21 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:29:21.613 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:29:21 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:29:21.617 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:29:21 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:29:21.637 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:29:21 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:29:21.641 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:29:21 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:29:21.721 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:29:21 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:29:21.726 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:29:21 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:29:21.750 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:29:21 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:29:21.756 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:29:21 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:29:22.892 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:29:22 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:29:22.894 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:29:22 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:29:22.894 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:29:22 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:29:22.896 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:29:22 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:29:22.898 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:29:22 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:29:22.900 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:29:22 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:29:22.901 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:29:22 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:29:23.560 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:29:23 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:29:23.562 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:29:23 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:29:23.563 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:29:23 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:29:23.565 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:29:23 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:29:23.567 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:29:23 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:29:23.568 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:29:23 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:29:23.569 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:29:23 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:29:23 DEBUG:Responses: []
05:29:23 DEBUG:Top Responses: []
05:29:23 DEBUG:Responses: []
05:29:23 DEBUG:Top Responses: []
05:29:23 DEBUG:[&#39;Two&#39;]
05:29:23 DEBUG:What is the minimun number of FAQ questions:

0: Two

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_input" class="doc_header"><code>get_input</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L149" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_input</code>(<strong><code>text</code></strong>)</p>
</blockquote>
<p>This redundancy is needed for testing</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="new_answer" class="doc_header"><code>new_answer</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L154" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>new_answer</code>(<strong><code>question</code></strong>, <strong><code>data</code></strong>, <strong><code>qa_models</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="question_response" class="doc_header"><code>question_response</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L185" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>question_response</code>(<strong><code>data</code></strong>, <strong><code>qa_models</code></strong>, <strong><code>num_returned_values_per_squad_model</code></strong>=<em><code>1</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">##Test FAQ dialog system&#39;s part</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">patch</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="k">def</span> <span class="nf">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">,</span> <span class="n">faq_dic</span><span class="p">):</span>

    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_faq.csv&#39;</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_config_faq.json&#39;</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">faqs</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">copyfile</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">faq</span><span class="o">.</span><span class="n">tfidf_logreg_en_faq</span><span class="p">,</span> <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">])</span>

    <span class="n">updates_faq_config_file</span><span class="p">(</span>
        <span class="n">configs_path</span><span class="o">=</span><span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">],</span>
        <span class="n">dataset_reader</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]}</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">mock_context_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">context_dic</span><span class="p">):</span>

    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_context.csv&#39;</span><span class="p">)</span>
    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.get_input&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_context_response_with_no_updates</span><span class="p">(</span><span class="n">mock_input</span><span class="p">):</span>
    <span class="n">mock_input</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Who is Enrique Jimenez?&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="s1">&#39;faq&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">)}</span>
    <span class="n">contexts</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;context&#39;</span><span class="p">:</span>
            <span class="p">[</span>
                <span class="s1">&#39;Intekglobal has its headquarters located in TJ&#39;</span><span class="p">,</span>
                <span class="s1">&#39;In Intekglobal we care about you&#39;</span><span class="p">,</span>
                <span class="sd">&#39;&#39;&#39;Enrique Jimenez is one of the smartest minds on the planet, </span>
<span class="sd">                   he currently works as Intekglobal employee&#39;&#39;&#39;</span>
            <span class="p">],</span>
        <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;headquarters&#39;</span><span class="p">,</span> <span class="s1">&#39;mission&#39;</span><span class="p">,</span> <span class="s1">&#39;Enrique</span><span class="se">\&#39;</span><span class="s1">s biography&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="n">faqs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Question&#39;</span><span class="p">:</span>
            <span class="p">[</span><span class="s1">&#39;Minimum number of questions?&#39;</span><span class="p">,</span> <span class="s1">&#39;This is the other question?&#39;</span><span class="p">],</span>
        <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Two&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">])</span>
        <span class="n">mock_context_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">])</span>

        <span class="n">qa_models</span> <span class="o">=</span> <span class="n">load_qa_models</span><span class="p">(</span>
            <span class="n">config_tfidf</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">][</span><span class="s1">&#39;config&#39;</span><span class="p">],</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">responses</span><span class="p">,</span> <span class="n">status</span> <span class="o">=</span> <span class="n">question_response</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">qa_models</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;  </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;  </span><span class="si">{</span><span class="n">responses</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="s1">&#39;no data updates..&#39;</span> <span class="o">==</span> <span class="n">status</span>
        <span class="k">assert</span> <span class="s1">&#39;one of the smartest minds on the planet&#39;</span> <span class="ow">in</span> <span class="n">responses</span>

<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.get_input&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_updating_faq_dataset</span><span class="p">(</span><span class="n">mock_input</span><span class="p">):</span>

    <span class="n">new_answer</span> <span class="o">=</span> <span class="s1">&#39;Intekglobal is one of the best companies in the world&#39;</span>
    <span class="n">mock_input</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;What is Intekglobal?&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">new_answer</span><span class="p">]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="s1">&#39;faq&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">)}</span>
    <span class="n">contexts</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;context&#39;</span><span class="p">:</span>
            <span class="p">[</span>
                <span class="sd">&#39;&#39;&#39;Tesla do important AI research. </span>
<span class="sd">                The goal is to make an automatic pilot.</span>
<span class="sd">                &#39;&#39;&#39;</span>
            <span class="p">],</span>
        <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Tesla AI&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="n">faqs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Question&#39;</span><span class="p">:</span>
            <span class="p">[</span><span class="s1">&#39;Who  owns Tesla Company?&#39;</span><span class="p">,</span> <span class="s1">&#39;Is this is heaven?&#39;</span><span class="p">],</span>
        <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Elon Musk is the owner of Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;No, it is life on earth&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">])</span>
        <span class="n">mock_context_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">])</span>

        <span class="n">qa_models</span> <span class="o">=</span> <span class="n">load_qa_models</span><span class="p">(</span>
            <span class="n">config_tfidf</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">][</span><span class="s1">&#39;config&#39;</span><span class="p">],</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">responses</span><span class="p">,</span> <span class="n">status</span> <span class="o">=</span> <span class="n">question_response</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">qa_models</span><span class="p">)</span>
        
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;  </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;  </span><span class="si">{</span><span class="n">responses</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="k">assert</span> <span class="s1">&#39;FAQ dataset and model updated..&#39;</span> <span class="o">==</span> <span class="n">status</span>

        <span class="n">updated_faq</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">][</span><span class="s1">&#39;path&#39;</span><span class="p">])</span>

        <span class="k">assert</span> <span class="n">updated_faq</span><span class="p">[</span><span class="n">updated_faq</span><span class="p">[</span><span class="s1">&#39;Answer&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">new_answer</span>
                              <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>

        
<span class="n">test_context_response_with_no_updates</span><span class="p">()</span>
<span class="n">test_updating_faq_dataset</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2020-06-17 17:29:28.775 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
05:29:28 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
2020-06-17 17:29:35.168 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
05:29:35 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
2020-06-17 17:29:36.623 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:29:36 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:29:36.722 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:29:36 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:29:36.826 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:29:36 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:29:36.901 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:29:36 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:29:48.245 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:29:48 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:29:48 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model
2020-06-17 17:30:05.554 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:30:05 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:30:05 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model
2020-06-17 17:30:40.971 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:30:40 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:30:41.10 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:30:41 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:30:41.12 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:30:41 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:30:41.22 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:30:41 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:30:41.414 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:30:41 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:30:41.425 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:30:41 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:30:41.432 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:30:41 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:30:41.439 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:30:41 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:30:42.189 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:30:42 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:30:42.193 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:30:42 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:30:42.219 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:30:42 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:30:42.228 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:30:42 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:30:42.920 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:30:42 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:30:42.921 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:30:42 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:30:42.922 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:30:42 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:30:42.924 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:30:42 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:30:42.926 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:30:42 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:30:42.927 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:30:42 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:30:42.928 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:30:42 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:30:43.565 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:30:43 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:30:43.566 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:30:43 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:30:43.567 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:30:43 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:30:43.568 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:30:43 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:30:43.570 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:30:43 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:30:43.571 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:30:43 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:30:43.572 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:30:43 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:30:44 DEBUG:Responses: [list([[&#39;Intekglobal&#39;], [0], [160.03579711914062]])
 list([[&#39;Intekglobal&#39;], [3], [244.86245727539062]])
 list([[&#39;one of the smartest minds on the planet&#39;], [19], [1664652.0]])]
05:30:44 DEBUG:Top Responses: [&#39;one of the smartest minds on the planet&#39;, &#39;Intekglobal&#39;]
05:30:47 DEBUG:Responses: [list([[&#39;&#39;], [-1], [0.0011892060283571482]])
 list([[&#39;&#39;], [-1], [0.01691678911447525]])
 list([[&#39;one of the smartest minds on the planet, \n                   he currently works as Intekglobal employee&#39;], [19], [18812.87109375]])]
05:30:47 DEBUG:Top Responses: [&#39;one of the smartest minds on the planet, \n                   he currently works as Intekglobal employee&#39;, &#39;&#39;]
05:30:47 DEBUG:  no data updates..
05:30:47 DEBUG:  Who is Enrique Jimenez?:

0: one of the smartest minds on the planet
1: one of the smartest minds on the planet, 
                   he currently works as Intekglobal employee
2: yes
3: Intekglobal

2020-06-17 17:30:49.789 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
05:30:49 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
2020-06-17 17:30:59.413 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
05:30:59 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
2020-06-17 17:31:04.512 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:31:04 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:31:05.287 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:31:05 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:31:05.410 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:31:05 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:31:05.498 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:31:05 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:31:16.623 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:31:16 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:31:16 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model
2020-06-17 17:31:34.90 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:31:34 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:31:34 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model
2020-06-17 17:31:51.194 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:51 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:51.199 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:31:51 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:31:51.203 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:51 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:51.255 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:31:51 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:31:51.263 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:51 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:51.268 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:51 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:51.271 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:51 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:51.274 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:51 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:51.276 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:31:51 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:31:51.277 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:51 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:51.284 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:31:51 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:31:51.286 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:51 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:51.942 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:51 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:51.943 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:31:51 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:31:51.944 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:51 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:51.946 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:51 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:51.948 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:51 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:51.950 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:31:51 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:31:51.951 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:51 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:52.588 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:52 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:52.589 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:31:52 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:31:52.590 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:52 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:52.592 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:52 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:52.594 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:52 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:52.595 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:31:52 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:31:52.596 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:52 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:53 DEBUG:Responses: [list([[&#39;AI research. \n                The goal is to make an automatic pilot&#39;], [19], [159.49786376953125]])]
05:31:53 DEBUG:Top Responses: [&#39;AI research. \n                The goal is to make an automatic pilot&#39;]
05:31:55 DEBUG:Responses: [list([[&#39;to make an automatic pilot&#39;], [61], [129.35693359375]])]
05:31:55 DEBUG:Top Responses: [&#39;to make an automatic pilot&#39;]
2020-06-17 17:31:56.319 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:56 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:56.321 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:31:56 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:31:56.321 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:56 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:56.382 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:31:56 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:31:56.391 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:56 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:56.399 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:56 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:56.403 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:56 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:56.407 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:56 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:56.410 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:31:56 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:31:56.411 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:56 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:56.421 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:31:56 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to &#39;auto&#39; in 0.22. Specify the multi_class option to silence this warning.
  &#34;this warning.&#34;, FutureWarning)
2020-06-17 17:31:56.423 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:56 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:57.611 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:57 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:57.612 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:31:57 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:31:57.613 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:57 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:57.615 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:57 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:57.616 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:57 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:57.617 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:31:57 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:31:57.618 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:57 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:58.313 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:31:58 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:31:58.314 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:31:58 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:31:58.314 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:58 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:31:58.316 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:31:58 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:31:58.318 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:31:58 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:31:58.319 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:31:58 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:31:58.319 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:58 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:31:58 DEBUG:  FAQ dataset and model updated..
05:31:58 DEBUG:  What is Intekglobal?:

0: No, it is life on earth
1: to make an automatic pilot
2: AI research. 
                The goal is to make an automatic pilot

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#tests</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">patch</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="k">def</span> <span class="nf">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">,</span> <span class="n">faq_dic</span><span class="p">):</span>

    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_faq.csv&#39;</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_config_faq.json&#39;</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">faqs</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">copyfile</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">faq</span><span class="o">.</span><span class="n">tfidf_logreg_en_faq</span><span class="p">,</span> <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">])</span>

    <span class="n">updates_faq_config_file</span><span class="p">(</span>
        <span class="n">configs_path</span><span class="o">=</span><span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">],</span>
        <span class="n">dataset_reader</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]}</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">mock_context_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">context_dic</span><span class="p">):</span>

    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_context.csv&#39;</span><span class="p">)</span>
    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.get_input&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_updated_faq_response</span><span class="p">(</span><span class="n">mock_input</span><span class="p">):</span>

    <span class="n">new_answer</span> <span class="o">=</span> <span class="s1">&#39;Intekglobal is one of the best companies in the world&#39;</span>
    <span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;What is Intekglobal?&#39;</span>
    <span class="n">mock_input</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="p">[</span><span class="n">question</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="n">new_answer</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="s1">&#39;faq&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">)}</span>
    <span class="n">contexts</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;context&#39;</span><span class="p">:</span>
            <span class="p">[</span>
                <span class="sd">&#39;&#39;&#39;One of the greatest punk rock bands from all the time</span>
<span class="sd">                is the Ramones.</span>
<span class="sd">                &#39;&#39;&#39;</span>
            <span class="p">],</span>
        <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Ramones&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="n">faqs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Question&#39;</span><span class="p">:</span>
            <span class="p">[</span><span class="s1">&#39;Who was the leading vocal artist of the Ramones?&#39;</span><span class="p">,</span> <span class="s1">&#39;Is this is heaven?&#39;</span><span class="p">],</span>
        <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Joey Ramone&#39;</span><span class="p">,</span> <span class="s1">&#39;No, it is life on earth&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">])</span>
        <span class="n">mock_context_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">])</span>

        <span class="n">qa_models</span> <span class="o">=</span> <span class="n">load_qa_models</span><span class="p">(</span>
            <span class="n">config_tfidf</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">][</span><span class="s1">&#39;config&#39;</span><span class="p">],</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">old_responses</span><span class="p">,</span> <span class="n">old_status</span> <span class="o">=</span> <span class="n">question_response</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">qa_models</span><span class="p">)</span>
        <span class="n">new_responses</span><span class="p">,</span> <span class="n">new_status</span> <span class="o">=</span> <span class="n">question_response</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">qa_models</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Old response:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">old_responses</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;New response:</span><span class="se">\n</span><span class="si">{</span><span class="n">new_responses</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        
        <span class="n">new_answer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">old_responses</span>
        <span class="n">new_answer</span> <span class="ow">in</span> <span class="n">new_responses</span>

<span class="n">test_updated_faq_response</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2020-06-17 17:32:14.295 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
05:32:14 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
2020-06-17 17:32:22.288 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
05:32:22 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
2020-06-17 17:32:23.642 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:32:23 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:32:23.744 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:32:23 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:32:23.838 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:32:23 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:32:23.906 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:32:23 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:32:35.314 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:32:35 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:32:35 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model
2020-06-17 17:32:54.676 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:32:54 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:32:54 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model
2020-06-17 17:33:02.424 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:02 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:02.425 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:02 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:02.426 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:02 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:02.456 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:33:02 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:33:02.459 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:02 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:02.462 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:02 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:02.463 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:02 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:02.466 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:02 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:02.467 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:02 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:02.468 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:02 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:02.476 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:33:02 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:33:02.478 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:02 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:03.123 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:03 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:03.124 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:03 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:03.125 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:03 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:03.127 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:03 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:03.129 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:03 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:03.130 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:03 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:03.131 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:03 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:03.796 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:03 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:03.798 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:03 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:03.798 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:03 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:03.801 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:03 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:03.802 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:03 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:03.804 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:03 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:03.804 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:03 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:05 DEBUG:Responses: [list([[&#39;greatest punk rock bands from all the time\n                is the Ramones&#39;], [11], [92.5745849609375]])]
05:33:05 DEBUG:Top Responses: [&#39;greatest punk rock bands from all the time\n                is the Ramones&#39;]
05:33:06 DEBUG:Responses: [list([[&#39;One of the greatest punk rock bands from all the time&#39;], [0], [0.04293891042470932]])]
05:33:06 DEBUG:Top Responses: [&#39;One of the greatest punk rock bands from all the time&#39;]
2020-06-17 17:33:07.674 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:07 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:07.675 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:07 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:07.676 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:07 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:07.683 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:33:07 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:33:07.685 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:07 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:07.688 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:07 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:07.689 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:07 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:07.691 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:07 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:07.693 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:07 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:07.694 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:07 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:07.700 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:33:07 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to &#39;auto&#39; in 0.22. Specify the multi_class option to silence this warning.
  &#34;this warning.&#34;, FutureWarning)
2020-06-17 17:33:07.702 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:07 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:08.373 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:08 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:08.375 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:08 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:08.377 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:08 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:08.379 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:08 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:08.381 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:08 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:08.383 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:08 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:08.384 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:08 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:09.54 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:09 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:09.55 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:09 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:09.56 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:09 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:09.58 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:09 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:09.60 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:09 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:09.62 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:09 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:09.63 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:09 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:09 DEBUG:Responses: [list([[&#39;greatest punk rock bands from all the time\n                is the Ramones&#39;], [11], [92.5745849609375]])]
05:33:09 DEBUG:Top Responses: [&#39;greatest punk rock bands from all the time\n                is the Ramones&#39;]
05:33:09 DEBUG:Responses: [list([[&#39;One of the greatest punk rock bands from all the time&#39;], [0], [0.04293891042470932]])]
05:33:09 DEBUG:Top Responses: [&#39;One of the greatest punk rock bands from all the time&#39;]
05:33:09 INFO:Old response:
 What is Intekglobal?:

0: No, it is life on earth
1: greatest punk rock bands from all the time
                is the Ramones
2: One of the greatest punk rock bands from all the time

05:33:09 INFO:New response:
What is Intekglobal?:

0: greatest punk rock bands from all the time
                is the Ramones
1: One of the greatest punk rock bands from all the time
2: Intekglobal is one of the best companies in the world

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test Contex Dialog System&#39;s part</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">patch</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>


<span class="k">def</span> <span class="nf">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">,</span> <span class="n">faq_dic</span><span class="p">):</span>

    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_faq.csv&#39;</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_config_faq.json&#39;</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">faqs</span><span class="p">)</span>
    <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">copyfile</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">faq</span><span class="o">.</span><span class="n">tfidf_logreg_en_faq</span><span class="p">,</span> <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">])</span>

    <span class="n">updates_faq_config_file</span><span class="p">(</span>
        <span class="n">configs_path</span><span class="o">=</span><span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;config&#39;</span><span class="p">],</span>
        <span class="n">dataset_reader</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;data_path&#39;</span><span class="p">:</span> <span class="n">faq_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]}</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">mock_context_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">context_dic</span><span class="p">):</span>

    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;temp_context.csv&#39;</span><span class="p">)</span>
    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
    <span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">context_dic</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.get_input&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_updated_context_response</span><span class="p">(</span><span class="n">mock_input</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="s1">&#39;faq&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">)}</span>

    <span class="n">contexts</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Intekglobal has its headquarters located in TJ&#39;</span><span class="p">,</span> <span class="p">],</span>
        <span class="s1">&#39;topic&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;headquarters&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="n">faqs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;Question&#39;</span><span class="p">:</span>
            <span class="p">[</span><span class="s1">&#39;Minimum number of questions?&#39;</span><span class="p">,</span> <span class="s1">&#39;This is the other question?&#39;</span><span class="p">],</span>
        <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Two&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="n">question</span> <span class="o">=</span> <span class="s1">&#39;What is a Chatbot?&#39;</span>
    <span class="n">new_topic</span> <span class="o">=</span> <span class="s1">&#39;AI Tool &amp; Chatbot Development&#39;</span>
    <span class="n">new_context</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>

<span class="s1">A chatbot is an important tool for simulating intelligent conversations with humans.</span>
<span class="s1">Intekglobal chatbots efficiently live message on platforms such as Facebook Messenger, </span>
<span class="s1">Slack, and Telegram. Assisting consumers with a variety of purposes and industries. </span>

<span class="s1">But chatbots are more than just a cool technology advancement. They actually transform the user experience.</span>
<span class="s1">People want simple and convenient interactions with interface and products.</span>

<span class="s1">&#39;&#39;&#39;</span>

    <span class="n">mock_input</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;YES&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">,</span> <span class="n">new_topic</span><span class="p">,</span> <span class="n">new_context</span><span class="p">,</span> <span class="n">question</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span>
    <span class="p">]</span>

    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>

        <span class="n">mock_faq_files</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">faqs</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">])</span>
        <span class="n">mock_context_file</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">])</span>

        <span class="n">qa_models</span> <span class="o">=</span> <span class="n">load_qa_models</span><span class="p">(</span>
            <span class="n">config_tfidf</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;faq&#39;</span><span class="p">][</span><span class="s1">&#39;config&#39;</span><span class="p">],</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">old_responses</span><span class="p">,</span> <span class="n">old_status</span> <span class="o">=</span> <span class="n">question_response</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">qa_models</span><span class="p">)</span>
        <span class="n">new_responses</span><span class="p">,</span> <span class="n">new_status</span> <span class="o">=</span> <span class="n">question_response</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">qa_models</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Old status: </span><span class="si">{</span><span class="n">old_status</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Old response:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{</span><span class="n">old_responses</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;New response:</span><span class="se">\n</span><span class="si">{</span><span class="n">new_responses</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">updated_context</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">][</span><span class="s1">&#39;path&#39;</span><span class="p">])</span>

        <span class="k">assert</span> <span class="n">updated_context</span><span class="p">[</span><span class="n">updated_context</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">new_context</span>
                              <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="k">assert</span> <span class="n">updated_context</span><span class="p">[</span><span class="n">updated_context</span><span class="p">[</span><span class="s1">&#39;topic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">new_topic</span>
                              <span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="k">assert</span> <span class="s1">&#39;an important tool for simulating intelligent conversations with humans&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">old_responses</span>
        <span class="k">assert</span> <span class="s1">&#39;an important tool for simulating intelligent conversations with humans&#39;</span> <span class="ow">in</span> <span class="n">new_responses</span>


<span class="n">test_updated_context_response</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2020-06-17 17:33:11.461 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
05:33:11 INFO:SquadVocabEmbedder: loading saved tokens vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/vocab_embedder.pckl
2020-06-17 17:33:17.404 INFO in &#39;deeppavlov.models.preprocessors.squad_preprocessor&#39;[&#39;squad_preprocessor&#39;] at line 310: SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
05:33:17 INFO:SquadVocabEmbedder: loading saved chars vocab from /home/jovyan/.deeppavlov/models/squad_model/emb/char_vocab_embedder.pckl
2020-06-17 17:33:18.499 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:33:18 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:33:18.598 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:33:18 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:33:18.700 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:33:18 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:33:18.774 INFO in &#39;deeppavlov.core.layers.tf_layers&#39;[&#39;tf_layers&#39;] at line 615: 
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
05:33:18 INFO:
Warning! tf.contrib.cudnn_rnn.CudnnCompatibleGRUCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnGRUCell later. 
2020-06-17 17:33:29.840 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:33:29 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_model/model]
05:33:29 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_model/model
2020-06-17 17:33:45.985 INFO in &#39;deeppavlov.core.models.tf_model&#39;[&#39;tf_model&#39;] at line 51: [loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:33:45 INFO:[loading model from /home/jovyan/.deeppavlov/models/squad_bert/model]
05:33:46 INFO:Restoring parameters from /home/jovyan/.deeppavlov/models/squad_bert/model
2020-06-17 17:33:53.70 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:53 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:53.72 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:53 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:53.73 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:53 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:53.80 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer
05:33:53 INFO:Fitting model sklearn.feature_extraction.textTfidfVectorizer
2020-06-17 17:33:53.82 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:53 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:53.85 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:53 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:53.86 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 101: [saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:53 INFO:[saving vocabulary to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:53.88 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:53 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:53.89 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:53 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:53.90 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:53 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:53.96 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression
05:33:53 INFO:Fitting model sklearn.linear_model.logisticLogisticRegression
/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)
2020-06-17 17:33:53.98 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 241: Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:53 INFO:Saving model to /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:53.733 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:53 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:53.734 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:53 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:53.735 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:53 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:53.737 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:53 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:53.739 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:53 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:53.740 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:53 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:53.741 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:53 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:54.843 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
05:33:54 INFO:Loading model sklearn.feature_extraction.text:TfidfVectorizer from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl
2020-06-17 17:33:54.844 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
05:33:54 INFO:Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters
2020-06-17 17:33:54.844 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:54 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
2020-06-17 17:33:54.847 INFO in &#39;deeppavlov.core.data.simple_vocab&#39;[&#39;simple_vocab&#39;] at line 115: [loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
05:33:54 INFO:[loading vocabulary from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]
2020-06-17 17:33:54.848 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 203: Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
05:33:54 INFO:Loading model sklearn.linear_model:LogisticRegression from /home/jovyan/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl
2020-06-17 17:33:54.850 INFO in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
05:33:54 INFO:Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters
2020-06-17 17:33:54.851 WARNING in &#39;deeppavlov.models.sklearn.sklearn_component&#39;[&#39;sklearn_component&#39;] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:54 WARNING:Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter
05:33:55 DEBUG:Responses: [list([[&#39;Intekglobal&#39;], [0], [31.67441177368164]])]
05:33:55 DEBUG:Top Responses: [&#39;Intekglobal&#39;]
05:33:57 DEBUG:Responses: [list([[&#39;&#39;], [-1], [0.005045291036367416]])]
05:33:57 DEBUG:Top Responses: [&#39;&#39;]
/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass &#39;sort=False&#39;.

To retain the current behavior and silence the warning, pass &#39;sort=True&#39;.

  sort=sort,
05:33:57 DEBUG:Responses: [list([[&#39;Intekglobal&#39;], [0], [31.67441177368164]])
 list([[&#39;an important tool for simulating intelligent conversations with humans&#39;], [15], [18000700.0]])]
05:33:57 DEBUG:Top Responses: [&#39;an important tool for simulating intelligent conversations with humans&#39;, &#39;Intekglobal&#39;]
05:33:58 DEBUG:Responses: [list([[&#39;&#39;], [-1], [0.005045291036367416]])
 list([[&#39;an important tool for simulating intelligent conversations with humans&#39;], [15], [2104.719482421875]])]
05:33:58 DEBUG:Top Responses: [&#39;an important tool for simulating intelligent conversations with humans&#39;, &#39;&#39;]
05:33:58 INFO:Old status: contexts dataset updated..
05:33:58 INFO:Old response:
 What is a Chatbot?:

0: yes
1: Intekglobal

05:33:58 INFO:New response:
What is a Chatbot?:

0: yes
1: Intekglobal
2: an important tool for simulating intelligent conversations with humans

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="set_minimal_faq_questions" class="doc_header"><code>set_minimal_faq_questions</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L195" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>set_minimal_faq_questions</code>(<strong><code>data</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="set_minimal_contexts" class="doc_header"><code>set_minimal_contexts</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L216" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>set_minimal_contexts</code>(<strong><code>data</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="set_data_dict" class="doc_header"><code>set_data_dict</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L227" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>set_data_dict</code>(<strong><code>file</code></strong>, <strong><code>data</code></strong>, <strong><code>question_type</code></strong>, <strong><code>data_dir</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_and_prepare_data" class="doc_header"><code>load_and_prepare_data</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L242" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_and_prepare_data</code>(<strong><code>context_data_file</code></strong>, <strong><code>faq_data_file</code></strong>, <strong><code>data</code></strong>, <strong><code>configs_faq</code></strong>=<em><code>PosixPath('/opt/conda/lib/python3.7/site-packages/deeppavlov/configs/faq/tfidf_logreg_en_faq.json')</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#tests</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">rmtree</span>
<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">patch</span>


<span class="k">def</span> <span class="nf">test_set_minimal_faqs_with_more_than_one_question</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>
        <span class="n">data_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;tmp_data.csv&#39;</span><span class="p">)</span>
        <span class="n">questions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a?&#39;</span><span class="p">,</span> <span class="s1">&#39;b?&#39;</span><span class="p">]</span>
        <span class="n">answers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Question&#39;</span><span class="p">:</span> <span class="n">questions</span><span class="p">,</span> <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="n">answers</span><span class="p">})</span>
        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;df&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">,</span> <span class="s1">&#39;path&#39;</span><span class="p">:</span> <span class="n">data_file</span><span class="p">}</span>
        <span class="n">set_minimal_faq_questions</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>


<span class="k">def</span> <span class="nf">test_set_minimal_faqs_with_less_than_two_questions</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>
        <span class="n">data_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;tmp_data.csv&#39;</span><span class="p">)</span>
        <span class="n">questions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a?&#39;</span><span class="p">]</span>
        <span class="n">answers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Question&#39;</span><span class="p">:</span> <span class="n">questions</span><span class="p">,</span> <span class="s1">&#39;Answer&#39;</span><span class="p">:</span> <span class="n">answers</span><span class="p">})</span>
        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;df&#39;</span><span class="p">:</span> <span class="n">df</span><span class="p">,</span> <span class="s1">&#39;path&#39;</span><span class="p">:</span> <span class="n">data_file</span><span class="p">}</span>

        <span class="k">assert</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="n">set_minimal_faq_questions</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">assert</span> <span class="nb">any</span><span class="p">(</span>
            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">Question</span> <span class="o">==</span> <span class="s1">&#39;Is this the Intekglobal Dialog System?&#39;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">test_set_minimal_contexts</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>
        <span class="n">data_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;tmp_data.csv&#39;</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;df&#39;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(),</span> <span class="s1">&#39;path&#39;</span><span class="p">:</span> <span class="n">data_file</span><span class="p">}</span>
        <span class="n">set_minimal_contexts</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">])</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;df&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;topic&#39;</span><span class="p">,</span> <span class="s1">&#39;context&#39;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">test_set_data_dict_no_file</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">)}</span>
        <span class="n">set_data_dict</span><span class="p">(</span>
            <span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">],</span>
            <span class="n">data_dir</span><span class="o">=</span><span class="n">tmpdirname</span><span class="p">,</span>
            <span class="n">question_type</span><span class="o">=</span><span class="s1">&#39;context&#39;</span>
        <span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;context&#39;</span><span class="p">][</span><span class="s1">&#39;path&#39;</span><span class="p">])</span>


<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.popen&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_load_and_prepare_data</span><span class="p">(</span><span class="n">mock_popen</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdirname</span><span class="p">:</span>
        <span class="n">mock_popen</span><span class="p">(</span><span class="s2">&quot;dirname $PWD&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="p">[</span><span class="n">tmpdirname</span><span class="p">]</span>
        <span class="n">tmp_config_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;tmp_file.json&#39;</span><span class="p">)</span>

        <span class="n">copyfile</span><span class="p">(</span><span class="n">configs</span><span class="o">.</span><span class="n">faq</span><span class="o">.</span><span class="n">tfidf_logreg_en_faq</span><span class="p">,</span> <span class="n">tmp_config_file</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;context&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="s1">&#39;faq&#39;</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">str</span><span class="p">)}</span>

        <span class="n">load_and_prepare_data</span><span class="p">(</span>
            <span class="n">context_data_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">faq_data_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">configs_faq</span><span class="o">=</span><span class="n">tmp_config_file</span>
        <span class="p">)</span>
        <span class="n">data_dir</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tmpdirname</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>


<span class="n">test_set_minimal_faqs_with_more_than_one_question</span><span class="p">()</span>
<span class="n">test_set_minimal_faqs_with_less_than_two_questions</span><span class="p">()</span>
<span class="n">test_set_minimal_contexts</span><span class="p">()</span>
<span class="n">test_set_data_dict_no_file</span><span class="p">()</span>
<span class="n">test_load_and_prepare_data</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>05:33:59 INFO: File created at /tmp/tmpb2wwhwsu/tmp_data.csv
05:33:59 INFO: File created at /tmp/tmpevqzpujs/tmp_data.csv
05:33:59 INFO: File created at /tmp/tmp6rbnxium/context_data.csv
05:33:59 DEBUG:{&#39;context&#39;: defaultdict(&lt;class &#39;str&#39;&gt;, {&#39;path&#39;: &#39;/tmp/tmp6rbnxium/context_data.csv&#39;, &#39;df&#39;: Empty DataFrame
Columns: [topic, context]
Index: []})}
05:33:59 INFO:Data directory created at /tmp/tmpvefeasqk/data
05:33:59 INFO: File created at /tmp/tmpvefeasqk/data/faq_data.csv
05:33:59 INFO: File created at /tmp/tmpvefeasqk/data/context_data.csv
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="dialog_system" class="doc_header"><code>dialog_system</code><a href="https://github.com/kikejimenez/let_me_answer_for_you/tree/master/let_me_answer_for_you/dialog_system.py#L277" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>dialog_system</code>(<strong><code>context_data_file</code></strong>=<em><code>None</code></em>, <strong><code>faq_data_file</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Main Dialog System</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test  dialog_system()</span>

<span class="kn">from</span> <span class="nn">unittest.mock</span> <span class="kn">import</span> <span class="n">patch</span>

<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.run_shell_installs&#39;</span><span class="p">)</span>
<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.load_qa_models&#39;</span><span class="p">)</span>
<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.load_and_prepare_data&#39;</span><span class="p">)</span>
<span class="nd">@patch</span><span class="p">(</span><span class="s1">&#39;__main__.question_response&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">test_main_keyboard_interrupt</span><span class="p">(</span>
    <span class="n">mock_question_response</span><span class="p">,</span>
    <span class="n">mock_pd_read_csv</span><span class="p">,</span>
    <span class="n">mock_load_qa_models</span><span class="p">,</span>
    <span class="n">mock_run_shell_installs</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">mock_question_response</span><span class="o">.</span><span class="n">side_effect</span> <span class="o">=</span> <span class="p">[</span>
        <span class="ne">KeyboardInterrupt</span><span class="p">(),</span> <span class="ne">EOFError</span><span class="p">(),</span>
        <span class="ne">SystemExit</span><span class="p">()</span>
    <span class="p">]</span>
    <span class="k">assert</span> <span class="s1">&#39;Goodbye!&#39;</span> <span class="o">==</span> <span class="n">dialog_system</span><span class="p">()</span>
    <span class="k">assert</span> <span class="s1">&#39;Goodbye!&#39;</span> <span class="o">==</span> <span class="n">dialog_system</span><span class="p">()</span>
    <span class="k">assert</span> <span class="s1">&#39;Goodbye!&#39;</span> <span class="o">==</span> <span class="n">dialog_system</span><span class="p">()</span>


<span class="n">test_main_keyboard_interrupt</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>05:34:00 DEBUG:Goodbye!
05:34:00 DEBUG:Goodbye!
05:34:00 DEBUG:Goodbye!
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

